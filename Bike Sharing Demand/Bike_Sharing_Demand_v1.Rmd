---
title: "Bike Sharing Demand"
output: 
    html_notebook:
        author: Paresh Pradhan
        theme: readable
---

## Introduction
We have to predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.

```{r start, message=FALSE, warning=FALSE}
require(plyr)
detach(package:plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(caret)
library(randomForest)
library(lubridate)
library(scales)
library(ggcorrplot)
library(parallel)
library(doParallel)
```

```{r read_data}
train.data <- tbl_df(read.csv('./Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('./Input/test.csv', stringsAsFactors = F))
```

## Data Pre-processing, Cleaning & Feature Extraction

```{r pre_process_start, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
str(train.data)
summary(train.data)
```

Replacing season codes with corresponding values.

```{r season}
season.list <- c('spring', 'summer', 'fall', 'winter')

replace_season <- function(df){
    df[['season']] <- plyr::mapvalues(df[['season']], 
                                  from = c(1, 2, 3, 4), 
                                  to = season.list)
    return(df)
}

train.data <- replace_season(train.data)
```

Creating Weather matrix as follows:  
weather 1: clear, partly_cloudy,  
weather 2: mist, cloudy, partly_cloudy  
weather 3: light_snow_rain, thunderstorm, partly_cloudy  
weather 4: heavy_snow_rain_ice_fog, mist, thunderstorm

```{r weather_matrix}
train.data <- train.data %>%
    mutate(clear = 0, partly_cloudy = 0, mist = 0, cloudy = 0, 
           light_snow_rain = 0, thunderstorm = 0, heavy_snow_rain_ice_fog = 0)

weather_matrix <- function(df){
    df[['clear']]                   <- ifelse(df[['weather']] == 1, 1, 0)
    df[['partly_cloudy']]           <- ifelse(df[['weather']] %in% c(1, 2, 3), 1, 0)
    df[['mist']]                    <- ifelse(df[['weather']] %in% c(2, 4), 1, 0)
    df[['cloudy']]                  <- ifelse(df[['weather']] == 2, 1, 0)
    df[['light_snow_rain']]         <- ifelse(df[['weather']] == 3, 1, 0)
    df[['thunderstorm']]            <- ifelse(df[['weather']] %in% c(3, 4), 1, 0)
    df[['heavy_snow_rain_ice_fog']] <- ifelse(df[['weather']] == 4, 1, 0)
    
    return(df)
}

train.data <- weather_matrix(train.data)
```

Splitting datetime into year, month, day_num, day_name, hour

```{r split_date}
train.data <- train.data %>%
    mutate(date.year = 0, date.month = '', month.day = 0, 
           week.day = '', day.hour = 0)

split_date <- function(df){
    df[['date.year']] = year(df[['datetime']])
    df[['date.month']] = month(df[['datetime']], label = T)
    df[['month.day']] = day(df[['datetime']])
    df[['week.day']] = wday(df[['datetime']], label = T)
    df[['day.hour']] = hour(df[['datetime']])
    
    return(df)
}

train.data <- split_date(train.data)
```

Adding new column, temp.diff <- atemp - temp

```{r temp_diff}
train.data <- train.data %>%
    mutate(temp.diff = atemp - temp)
```

Adding new column, day.type -- working day, holiday or weekend

```{r day_type}
train.data <- train.data %>%
    mutate(day.type = NA)

day_type <- function(df){
    df[['day.type']] <- ifelse(df[['holiday']] == 1, 'Holiday',
                               ifelse(df[['workingday']] == 1, 'Workingday', 
                                      'Weekend'))
    return(df)
}

train.data <- day_type(train.data)
```

Converting columns into factors

```{r convert_factor}
train.data[c(2:5, 13:24, 26)] <- lapply(train.data[c(2:5, 13:24, 26)], factor)
```

Now lets check the data again

```{r pre_process_end}
summary(train.data)
```

## Data Exploration
First lets check the proportion of casual to registered users
```{r explore_start}
train.data %>% mutate(casual.users = sum(casual), 
                      registered.users = sum(registered)) %>%
    select(casual.users, registered.users) %>%
    distinct(casual.users, registered.users) %>%
    prop.table()
```

### No. of Users by Season
Lets check the effect of seasons on the users

```{r explore1, fig.height=4, fig.width=8, fig.align='center'}
users.by.season <- train.data %>% 
    group_by(season) %>%
    mutate(casual.users = sum(casual), 
           registered.users = sum(registered)) %>%
    select(season, casual.users, registered.users) %>%
    distinct(season, casual.users, registered.users) %>%
    gather(key = user.type, value = user.count, casual.users:registered.users)

plot.users.by.season <- ggplot(users.by.season, 
                          mapping = aes(season, user.count, 
                                        fill = user.type)) +
    geom_bar(stat = 'identity', position = 'dodge', width = 0.7) +
    scale_y_continuous(labels = comma) +
    coord_flip() +
    ggtitle('No. of Users by Season')

plot.users.by.season
```

It seems less people ride bicycles during Spring season than other seasons.

In winter and spring the proportion of casual users decreases in comparision to registered users.

### No. of Users by Weather
Lets check the user count by weather

```{r explore2, fig.height=4, fig.width=9, fig.align='center'}
users.by.weather <- train.data %>% 
    gather(key = weather.type, value = value, 
           clear:heavy_snow_rain_ice_fog) %>%
    filter(value > 0) %>%
    group_by(weather.type) %>%
    mutate(casual.users = sum(casual), 
           registered.users = sum(registered)) %>%
    select(weather.type, casual.users, registered.users) %>%
    distinct(weather.type, casual.users, registered.users) %>%
    gather(key = user.type, value = user.count, 
           casual.users:registered.users)

plot.users.by.weather <- ggplot(users.by.weather, 
                          mapping = aes(reorder(weather.type, user.count), 
                                        user.count, fill = user.type)) +
    geom_bar(stat = 'identity', width = 0.8) +
    scale_y_continuous(labels = comma) +
    coord_flip() +
    xlab('weather type') +
    ggtitle('No. of Users by Weather')

plot.users.by.weather
```

Most people ride during good weather (Clear, Partly Cloudy). Only the most dedicated ride in bad weather (Thunderstorm, Light snow or Rain).

### No. of Users over Days of Week
Lets check user count over days of week

```{r explore3, fig.height=5, fig.width=8, fig.align='center'}
users.over.days.of.week <- train.data %>%
    group_by(week.day) %>%
    mutate(casual.users = sum(casual), 
           registered.users = sum(registered)) %>%
    select(week.day, casual.users, registered.users) %>%
    distinct(week.day, casual.users, registered.users) %>%
    gather(key = user.type, value = user.count, 
           casual.users:registered.users)

plot.users.over.days.of.week <- 
    ggplot(users.over.days.of.week, 
           mapping = aes(x = week.day, y = user.count/1000, 
                         fill = user.type)) +
    geom_bar(stat = 'identity') +
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'No. of Users over Days of Week', 
            subtitle = '(User count is in thousands)')

plot.users.over.days.of.week
```

While the overall count of users remains pretty much the same over the week, more casual users ride bicycles on weekends; and the registered users prefer to ride during the weekdays.

### No. of Users based on Hour of Day
Lets check what time of the day most users ride.

```{r explore4, fig.height=4, fig.width=10, fig.align='center'}
users.by.hour.of.day <- train.data %>%
    group_by(day.hour) %>%
    mutate(casual.users = sum(casual), 
           registered.users = sum(registered)) %>%
    select(day.hour, casual.users, registered.users) %>%
    distinct(day.hour, casual.users, registered.users) %>%
    gather(key = user.type, value = user.count, 
           casual.users:registered.users)

plot.users.by.hour.of.day <- 
    ggplot(users.by.hour.of.day, 
           mapping = aes(x = day.hour, y = user.count/1000, 
                         fill = user.type)) +
    geom_bar(stat = 'identity') +
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'No. of Users by Hour of Day', 
            subtitle = '(User count is in thousands)')

plot.users.by.hour.of.day
```

As expected, most users ride between 6 AM to 11 PM. The bicycle use peaks at 8 AM and between 4 PM to 7 PM. 

There is a consistent level of bicycle use from 7 AM to 8 PM, with only a slight dip at 10 AM. After 8 PM, the usage slowly decreases.

### No. of Users based on Hour of Day by Season
Lets see if the usage pattern changes in different seasons.

```{r explore5, fig.height=5, fig.width=12, fig.align='center'}
users.by.hour.of.day.by.season <- train.data %>%
    group_by(season, day.hour) %>%
    mutate(casual.users = sum(casual), 
           registered.users = sum(registered)) %>%
    select(season, day.hour, casual.users, registered.users) %>%
    distinct(season, day.hour, casual.users, registered.users) %>%
    gather(key = user.type, value = user.count, 
           casual.users:registered.users)

plot.users.by.hour.of.day.by.season <- 
    ggplot(users.by.hour.of.day.by.season, 
           mapping = aes(x = day.hour, y = user.count/1000, 
                         fill = user.type)) +
    geom_bar(stat = 'identity') +
    facet_wrap(~ season) +
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'No. of Users by Hour of Day by Season', 
            subtitle = '(User count is in thousands)')

plot.users.by.hour.of.day.by.season
```

Nothing new here. We already knew that there are less users overall during Spring. The usage pattern by hour of day is same in all 4 seasons.

### Correlaton between Temperature, Humidity, Windspeed and User Count

Lets see the correlation between Temperature, Humidity, Windspeed and User Count.

```{r explore6, fig.align='center', fig.height=5, fig.width=5}
corr.temp.hum.wind.user <- train.data %>%
    select(atemp, humidity, windspeed, count) %>%
    distinct() %>% cor() %>% round(digits = 1)

plot.corr.temp.hum.wind.user <- 
    ggcorrplot(corr = corr.temp.hum.wind.user, method = 'circle', 
               type = 'lower', hc.order = T, lab = T, lab_size = 4, 
               ggtheme = theme_bw, 
               title = 'Correlaton between Temp, Humidity, Windspeed & UserCount')

plot.corr.temp.hum.wind.user
```

User Count seems to have positive correlation to Temperature and negative to humidity.

## Model Training, Prediction & Evaluation - 1

We will use Random Forest to train our model.

Preparing the feature dataset.

```{r feature_data}
feature.train <- train.data %>%
    select(season, atemp, humidity, windspeed, clear, partly_cloudy,
           mist, cloudy, light_snow_rain, thunderstorm, heavy_snow_rain_ice_fog,
           date.year, date.month, month.day, week.day, day.hour, day.type,
           count) %>%
    distinct()
```

Splitting training and testing datasets

```{r train_test_split}
set.seed(777)
inTraining <- createDataPartition(feature.train$count, p = 0.75, list = F)
training <- feature.train[inTraining, ]
testing <- feature.train[-inTraining, ]
```

Training model

```{r train_model}
set.seed(777)
fit.rf <- randomForest(formula = count ~ ., data =  training,
                       ntree = 200, importance = T)
```

Feature Importance
```{r feature_importance}
feature.imp <- as.data.frame(fit.rf$importance)
feature.imp <- cbind(feature.name = rownames(feature.imp), feature.imp)
qplot(feature.imp$IncNodePurity, feature.imp$feature.name, 
      xlab = 'Feature Name', ylab = 'Importance')
```



Lets run the model on our testing split.

```{r testing}
predict.rf <- predict(fit.rf, newdata = testing)
```

Lets evaluate our model

```{r rmse}
RMSE(pred = predict.rf, obs = testing$count)
```


## Model Training, Prediction & Evaluation - 2

We will use Random Forest to train our model.

First we will Configure parallel processing

```{r parallel_cluster2}
# clusters <- makeCluster(detectCores() - 1)
# registerDoParallel(clusters)
```


Preparing the feature dataset.

```{r feature_data2}
# feature.train <- train.data %>%
#     select(season, atemp, humidity, windspeed, clear, partly_cloudy,
#            mist, cloudy, light_snow_rain, thunderstorm, heavy_snow_rain_ice_fog,
#            date.year, date.month, month.day, week.day, day.hour, day.type,
#            count) %>%
#     distinct()
```

Splitting training and testing datasets

```{r train_test_split2}
# set.seed(777)
# inTraining <- createDataPartition(feature.train$count, p = 0.75, list = F)
# training <- feature.train[inTraining, ]
# testing <- feature.train[-inTraining, ]
```

Setting train control and grid parameters

```{r train_control2}
# tr.ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5, 
#                         verboseIter = T, allowParallel = T)
# 
# grid.rf <- expand.grid(.mtry = c(2, 4, 8, 17))
```

Training model

```{r train_model2}
# set.seed(777)
# fit.rf <- train(x = training[, -18], y = training[, 18], method = 'rf', 
#                 trControl = tr.ctrl, tuneGrid = grid.rf)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop2}
# stopCluster(clusters)
# registerDoSEQ()
```

Lets run the model on our testing split.

```{r testing2}
#predict.rf <- predict(fit.rf, newdata = testing)
```

Lets evaluate our model

```{r confusion_matrix2}
#RMSE(pred = predict.rf, obs = testing$count)
```



