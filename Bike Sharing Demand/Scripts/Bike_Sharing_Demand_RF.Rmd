---
title: "Bike Sharing Demand"
output: 
    html_notebook:
        author: Paresh Pradhan
        theme: readable
---

# Introduction
We have to predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.

We will use Caret package's Random Forest to model the data.

```{r start, message=FALSE, warning=FALSE}
require(plyr)
detach(package:plyr)
library(tidyverse)
library(lubridate)
library(broom)
library(caret)
library(scales)
library(ggcorrplot)
library(parallel)
library(doParallel)
library(gridExtra)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(mosaic)
library(GGally)
```

# Trial-0

### Data Preparation

```{r t0_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Converting to factors:

```{r t0_to_factor}
# names(train.data)
train.data[c(2:5)] <- 
    lapply(X = train.data[c(2:5)], FUN = factor)

# names(test.data)
test.data[c(2:5)] <- 
    lapply(X = test.data[c(2:5)], FUN = factor)
```

Checking Data:

```{r t0_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t0_feature_set}
names(train.data)
feature.list <- c(2:9)
length(feature.list)
```

Creating training and testing splits

```{r t0_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t0_model_fit1, results='hide'}
set.seed(777)
fit.rf.cas0 <- randomForest(x = training[feature.list], y = training$casual,
                               ntree = 500, importance = T, do.trace = T)
```

```{r t0_model_fit2, results='hide'}
set.seed(777)
fit.rf.reg0 <- randomForest(x = training[feature.list], y = training$registered,
                               ntree = 500, importance = T, do.trace = T)
```

### Model Evaluation

feature importance:

```{r t0_var_imp1}
tidy(fit.rf.cas0$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t0_var_imp2}
tidy(fit.rf.reg0$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t0_predict}
predict.rf.cas0 <- predict(fit.rf.cas0, newdata = testing[feature.list])
predict.rf.reg0 <- predict(fit.rf.reg0, newdata = testing[feature.list])
predict.rf.count0 <- predict.rf.cas0 + predict.rf.reg0
```

Scoring the models:

```{r t0_model_eval1}
RMSE(pred = predict.rf.cas0, obs = testing$casual)
```

```{r t0_model_eval2}
RMSE(pred = predict.rf.reg0, obs = testing$registered)
```

```{r t0_model_eval3}
RMSE(pred = predict.rf.count0, obs = testing$count)
```

### Error Discovery

Creating Error data:

```{r t0_error_data}
error.data0 <- testing %>%
    mutate(predict.cas = predict.rf.cas0, 
           predict.reg = predict.rf.reg0) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t0_error_explore1}
error.data0 %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point() +
    ggtitle('Error Plot - Casual')
```

```{r t0_error_explore2}
error.data0 %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point() +
    ggtitle('Error Plot - Registered')
```







# Trial-1

### Data Preparation

```{r t1_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t1_split_date}

split_date <- function(df){
    df[['year']] = year(df[['datetime']])
    df[['month']] = month(df[['datetime']])
    df[['month.day']] = day(df[['datetime']])
    df[['week.day']] = wday(df[['datetime']])
    df[['hour']] = hour(df[['datetime']])
    df[['month.name']] = month(df[['datetime']], label = T)
    df[['week.day.name']] = wday(df[['datetime']], label = T)
    
    return(df)
}

train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t1_day_type}

day_type <- function(df){
    df[['day.type']] <- ifelse(df[['holiday']] == 1, 1,
                               ifelse(df[['workingday']] == 1, 2, 
                                      3))
    df[['day.type.name']] <- ifelse(df[['day.type']] == 1, 'Holiday',
                               ifelse(df[['day.type']] == 2, 'Workingday', 
                                      'Weekend'))
    return(df)
}

train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t7_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```


Checking distributions of Casual and Registered:

```{r t1_dist1}
train.data %>%
    ggplot(mapping = aes(x = casual)) +
    geom_density() +
    ggtitle('Distribution - Casual')
```

```{r t1_dist2}
train.data %>%
    ggplot(mapping = aes(x = registered)) +
    geom_density() +
    ggtitle('Distribution - Registered')
```

Both are highly right skewed.

Adding log of casual and registered:

```{r t1_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Checking distributions after log transformation:

```{r t1_dist3}
train.data %>%
    ggplot(mapping = aes(x = log.cas)) +
    geom_density() +
    ggtitle('Distribution - LogCasual')
```

```{r t1_dist4}
train.data %>%
    ggplot(mapping = aes(x = log.reg)) +
    geom_density() +
    ggtitle('Distribution - LogRegistered')
```

These are more normal.

Using decision tree to divide the hours into separate groups for casual and registered:

```{r t1_dtree_hour_group}
dtree.hrgroup.cas <- rpart(log.cas ~ hour, data = train.data)
fancyRpartPlot(dtree.hrgroup.cas)
```

```{r t1_hour_group1}
hour_group_cas <- function(df){
    
    df[['hour.group.cas']] [df[['hour']] < 1.5] <- '0to1'
    df[['hour.group.cas']] [df[['hour']] >= 1.5 & df[['hour']] < 6.5] <- '2to6'
    df[['hour.group.cas']] [df[['hour']] >= 6.5 & df[['hour']] < 7.5] <- '7to7'
    df[['hour.group.cas']] [df[['hour']] >= 7.5 & df[['hour']] < 10] <- '8to9'
    df[['hour.group.cas']] [df[['hour']] >= 10 & df[['hour']] < 20] <- '10to19'
    df[['hour.group.cas']] [df[['hour']] >= 20] <- '20to23'
    
    return(df)
}

train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t1_dtree_hour_group2}
dtree.hrgroup.reg <- rpart(log.reg ~ hour, data = train.data)
fancyRpartPlot(dtree.hrgroup.reg)
```

```{r t1_hour_group2}
hour_group_reg <- function(df){
    
    df[['hour.group.reg']] [df[['hour']] < 1.5] <- '0to1'
    df[['hour.group.reg']] [df[['hour']] >= 1.5 & df[['hour']] < 5.5] <- '2to5'
    df[['hour.group.reg']] [df[['hour']] >= 5.5 & df[['hour']] < 6.5] <- '6to6'
    df[['hour.group.reg']] [df[['hour']] >= 6.5 & df[['hour']] < 16] <- '7to15'
    df[['hour.group.reg']] [df[['hour']] >= 16 & df[['hour']] < 20] <- '16to19'
    df[['hour.group.reg']] [df[['hour']] >= 20 & df[['hour']] < 22] <- '20to21'
    df[['hour.group.reg']] [df[['hour']] >= 22] <- '22to23'
    
    return(df)
}

train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```

```{r t1_hour_group3, echo=FALSE}
# train.data %>% select(hour, hour.group.cas, hour.group.reg) %>% distinct()
```

Checking the distributions of Humidity and Windspeed:

```{r t1_dist5}
train.data %>% ggplot(aes(x = humidity)) + geom_density()
```

```{r t1_dist6}
train.data %>% ggplot(aes(x = windspeed)) + geom_density()
```

Using Decision trees to divide Humidity into groups for casual and registered.

```{r t1_dtree_hum_group1}
dtree.humgroup.cas <- rpart(log.cas ~ humidity, data = train.data)
fancyRpartPlot(dtree.humgroup.cas)
```

```{r t1_humidity_group1}
hum_group_cas <- function(df){
    
    df[['hum.group.cas']] [df[['humidity']] < 46] <- 'lt46'
    df[['hum.group.cas']] [df[['humidity']] >= 46 & 
                               df[['humidity']] < 74] <- '46to74'
    df[['hum.group.cas']] [df[['humidity']] >= 74 & 
                               df[['humidity']] < 84] <- '74to84'
    df[['hum.group.cas']] [df[['humidity']] >= 84] <- 'gt84'
    
    return(df)
}

train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```


```{r t1_dtree_hum_group2}
dtree.humgroup.reg <- rpart(log.reg ~ humidity, data = train.data)
fancyRpartPlot(dtree.humgroup.reg)
```

```{r t1_humidity_group2}
hum_group_reg <- function(df){
    
    df[['hum.group.reg']] [df[['humidity']] < 46] <- 'lt46'
    df[['hum.group.reg']] [df[['humidity']] >= 46 & 
                               df[['humidity']] < 62] <- '46to62'
    df[['hum.group.reg']] [df[['humidity']] >= 62 & 
                               df[['humidity']] < 84] <- '62to84'
    df[['hum.group.reg']] [df[['humidity']] >= 84] <- 'gt84'
    
    return(df)
}

train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t1_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Using Decision trees to divide Windspeed into groups for casual and registered.

```{r t1_dtree_wind_group1}
dtree.windgroup.cas <- rpart(log.cas ~ windspeed, data = train.data, 
                             control = rpart.control(cp = 0.0005))
fancyRpartPlot(dtree.windgroup.cas)
```

```{r t1_wind_group1}
wind_group_cas <- function(df){
    
    df[['wind.group.cas']] [df[['windspeed']] < 1 ] <- 'lt1'
    df[['wind.group.cas']] [df[['windspeed']] >= 1 & 
                               df[['windspeed']] < 6.5] <- '1to6.5'
    df[['wind.group.cas']] [df[['windspeed']] >= 6.5 & 
                               df[['windspeed']] < 10] <- '6.5to10'
    df[['wind.group.cas']] [df[['windspeed']] >= 10 & 
                               df[['windspeed']] < 14] <- '10to14'
    df[['wind.group.cas']] [df[['windspeed']] >= 14] <- 'gt14'
    
    return(df)
}

train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```


```{r t1_dtree_wind_group2}
dtree.windgroup.reg <- rpart(log.reg ~ windspeed, data = train.data, 
                             control = rpart.control(cp = 0.001))
fancyRpartPlot(dtree.windgroup.reg)
```

```{r t1_wind_group2}
wind_group_reg <- function(df){
    
    df[['wind.group.reg']] [df[['windspeed']] < 1 ] <- 'lt1'
    df[['wind.group.reg']] [df[['windspeed']] >= 1 & 
                               df[['windspeed']] < 6.5] <- '1to6.5'
    df[['wind.group.reg']] [df[['windspeed']] >= 6.5 & 
                               df[['windspeed']] < 10] <- '6.5to10'
    df[['wind.group.reg']] [df[['windspeed']] >= 10 & 
                               df[['windspeed']] < 14] <- '10to14'
    df[['wind.group.reg']] [df[['windspeed']] >= 14] <- 'gt14'
    
    return(df)
}

train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t1_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Dividing atemp into separate groups for casual and registered:

```{r t1_dtree_atemp_group1}
dtree.atemp.grp.cas <- rpart(log.cas ~ atemp, data = train.data)
fancyRpartPlot(dtree.atemp.grp.cas)
```

```{r t1_atemp_group1}
atemp_group_cas <- function(df){
    
    df[['atemp.group.cas']] [df[['atemp']] < 15] <- 'lt15'
    df[['atemp.group.cas']] [df[['atemp']] >= 15 & 
                               df[['atemp']] < 19] <- '15to19'
    df[['atemp.group.cas']] [df[['atemp']] >= 19 & 
                               df[['atemp']] < 30] <- '19to30'
    df[['atemp.group.cas']] [df[['atemp']] >= 30] <- 'gt30'
    
    return(df)
}

train.data <- atemp_group_cas(train.data)
test.data <- atemp_group_cas(test.data)
```

```{r t1_dtree_atemp_group2}
dtree.atemp.grp.reg <- rpart(log.reg ~ atemp, data = train.data)
fancyRpartPlot(dtree.atemp.grp.reg)
```

```{r t1_atemp_group2}
atemp_group_reg <- function(df){
    
    df[['atemp.group.reg']] [df[['atemp']] < 14] <- 'lt14'
    df[['atemp.group.reg']] [df[['atemp']] >= 14 & 
                               df[['atemp']] < 30] <- '14to30'
    df[['atemp.group.reg']] [df[['atemp']] >= 30] <- 'gt30'
    
    return(df)
}

train.data <- atemp_group_reg(train.data)
test.data <- atemp_group_reg(test.data)
```

```{r t1_atemp_group3}
# train.data %>% select(atemp, atemp.group.cas, atemp.group.reg) %>%
#     distinct() %>% arrange(atemp)
```


Adding new features:

```{r t1_new_features}
train.data$z.humidity2 <- zscore(train.data$humidity^2)
train.data$z.windspeed0.5 <- zscore(sqrt(train.data$windspeed))
train.data$hourgrp.daytype.cas <- paste(train.data$hour.group.cas, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.daytype.reg <- paste(train.data$hour.group.reg, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.atemp.cas <- paste(train.data$hour.group.cas, 
                                        train.data$atemp.group.cas, sep = ':')
train.data$hourgrp.atemp.reg <- paste(train.data$hour.group.reg, 
                                        train.data$atemp.group.reg, sep = ':')

test.data$z.humidity2 <- zscore(test.data$humidity^2)
test.data$z.windspeed0.5 <- zscore(sqrt(test.data$windspeed))
test.data$hourgrp.daytype.cas <- paste(test.data$hour.group.cas, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.daytype.reg <- paste(test.data$hour.group.reg, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.atemp.cas <- paste(test.data$hour.group.cas, 
                                   test.data$atemp.group.cas, sep = ':')
test.data$hourgrp.atemp.reg <- paste(test.data$hour.group.reg, 
                                   test.data$atemp.group.reg, sep = ':')
```


Adding Cube roots of casual and registered:

```{r t1_cube_root}
train.data$cas.cbrt <- (train.data$casual + 1) ^ (1/3)
train.data$reg.cbrt <- (train.data$registered + 1) ^ (1/3)
```


Converting to factors:

```{r t1_to_factor1}
names(train.data)
train.data[c(2:5, 13:22, 25:32, 35:38)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:32, 35:38)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))
```

```{r t1_to_factor2}
names(test.data)
test.data[c(2:5, 10:27, 30:33)] <- 
    lapply(X = test.data[c(2:5, 10:27, 30:33)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```


```{r t1_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t1_feature_set}
names(train.data)
feature.list.cas <- c(2:9, 13:22, 25, 27, 29, 31, 33:34, 35, 37)
feature.list.reg <- c(2:9, 13:22, 26, 28, 30, 32, 33:34, 36, 38)
length(feature.list.cas)
length(feature.list.reg)
```

Creating training and testing splits

```{r t1_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.85, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Control Parameters:

```{r t1_control_par}
tr.control <- trainControl(method = 'cv', number = 10, search = 'grid',  
                           verboseIter = T, allowParallel = T)
tune.grid.cas <- expand.grid(mtry = c(5, 10, 15, 26))
tune.grid.reg <- expand.grid(mtry = c(5, 10, 15, 26))
```

Starting Cluster:

```{r t1_start_cluster}
ncluster <- makeCluster(detectCores() - 1, type = 'PSOCK', outfile = '')
registerDoParallel(ncluster)
```

Fitting Models:

```{r t1_model_fit1, results='hide'}
set.seed(777)
fit.rf.cas1 <- train(x = training[feature.list.cas], y = training$cas.cbrt,
                     method = 'rf', importance = T,
                     do.trace = T, ntree = 300,
                     trControl = tr.control,
                     tuneGrid = tune.grid.cas
                     )
```

```{r t1_model_fit2, results='hide'}
set.seed(777)
fit.rf.reg1 <- train(x = training[feature.list.reg], y = training$reg.cbrt,
                     method = 'rf', importance = T,
                     do.trace = T, ntree = 300,
                     trControl = tr.control,
                     tuneGrid = tune.grid.reg
                     )
```


DStopping cluster:

```{r t1_stop_cluster}
stopCluster(ncluster)
registerDoSEQ()
```

### Model Evaluation

Model attributes:

```{r t1_fit_resamples}
summary(resamples(list(Casual = fit.rf.cas1,
                       Registered = fit.rf.reg1)))
```


Feature importance:

```{r t1_var_imp1}
varImp(fit.rf.cas1)[[1]] %>% 
    mutate(Var = rownames(.)) %>% 
    select(Var, Overall) %>%
    arrange(desc(Overall))
```

```{r t1_var_imp2}
varImp(fit.rf.reg1)[[1]] %>% 
    mutate(Var = rownames(.)) %>% 
    select(Var, Overall) %>%
    arrange(desc(Overall))
```

Lets run the model on our testing split.

```{r t1_predict}
predict.rf.cas1 <- predict(fit.rf.cas1, newdata = testing[feature.list.cas])
predict.rf.reg1 <- predict(fit.rf.reg1, newdata = testing[feature.list.reg])
predict.rf.count1 <- expm1(predict.rf.cas1) + expm1(predict.rf.reg1)
```

Scoring the models:

```{r t1_model_eval1}
RMSE(pred = expm1(predict.rf.cas1), obs = testing$casual)
```

```{r t1_model_eval2}
RMSE(pred = expm1(predict.rf.reg1), obs = testing$registered)
```

```{r t1_model_eval3}
RMSE(pred = predict.rf.count1, obs = testing$count)
```

### Error Discovery

Creating Error data:

```{r t1_error_data}
error.data1 <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas1), 
           predict.reg = expm1(predict.rf.reg1)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t1_error_explore1}
error.data1 %>% #filter(casual <= 30) %>%
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Casual')
```

```{r t1_error_explore2}
error.data1 %>% 
    filter(error.reg < 500) %>%
    #filter(registered <= 50) %>%
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t1_error_explore3, fig.height=6, fig.width=12}
error.data1 %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t1_error_explore4, fig.height=6, fig.width=12}
error.data1 %>% filter(error.reg < 500) %>%
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```


# Submission

Creating feature list:

```{r sub_feature} 
names(test.data)
feature.list.cas.test <- c(2:19, 20, 22, 24, 26, 28:29, 30, 32)
feature.list.reg.test <- c(2:19, 21, 23, 25, 27, 28:29, 31, 33)
```


Predicting using test data:

```{r sub_predict}
predict.rf.cas.test <- predict(fit.rf.cas1, 
                               newdata = test.data[feature.list.cas.test])
predict.rf.reg.test <- predict(fit.rf.reg1, 
                               newdata = test.data[feature.list.reg.test])
predict.rf.count.test <- expm1(predict.rf.cas.test) + expm1(predict.rf.reg.test)
```


Creating Submission Files

```{r sub_file}
test.data$count <- predict.rf.count.test

test.data %>% select(datetime, count) %>%
    write.csv(file = '../Output/submit_count_cv5.csv',
              quote = F, row.names = F)
```


