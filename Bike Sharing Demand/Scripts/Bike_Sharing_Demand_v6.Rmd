---
title: "Bike Sharing Demand"
output: 
    html_notebook:
        author: Paresh Pradhan
        theme: readable
---

## Introduction
We have to predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.

```{r start, message=FALSE, warning=FALSE}
require(plyr)
detach(package:plyr)
library(tidyverse)
library(lubridate)
library(broom)
library(caret)
library(scales)
library(ggcorrplot)
library(parallel)
library(doParallel)
library(gridExtra)
```

```{r read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

## Data Pre-processing, Cleaning & Feature Engineering

```{r pre_process_start, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
str(train.data)
summary(train.data)
```

One Hot Encoding Season.

```{r OHE_season}

OHE_season <- function(df){
    
    season.value = 1
    
    for (i in c('spring', 'summer', 'fall', 'winter')){
        
        df[[i]] <- ifelse(df[['season']] == season.value, 1, 0)
        season.value <- season.value + 1
        
    }
    
    return(df)
}

train.data <- OHE_season(train.data)
```

Adding weather codes as follows:  
weather 1: clear_partly_cloudy
weather 2: mist_cloudy
weather 3: light_snow_rain_thunderstorm
weather 4: heavy_snow_rain_ice_fog_thunderstorm

```{r OHE_weather}

OHE_weather <- function(df){
    
    weather.value = 1
    
    for (i in c('clear_partly_cloudy', 'mist_cloudy', 'light_snow_rain',
                'heavy_snow_rain')){
        
        df[[i]] <- ifelse(df[['weather']] == weather.value, 1, 0)
        weather.value <- weather.value + 1
        
    }
    
    return(df)
}

train.data <- OHE_weather(train.data)
```

Splitting datetime into year, month, day_num, weekday, hour

```{r split_date}

split_date <- function(df){
    df[['year']] = year(df[['datetime']])
    df[['month']] = month(df[['datetime']])
    df[['month.day']] = day(df[['datetime']])
    df[['week.day']] = wday(df[['datetime']])
    df[['hour']] = hour(df[['datetime']])
    df[['month.name']] = month(df[['datetime']], label = T)
    df[['week.day.name']] = wday(df[['datetime']], label = T)
    
    return(df)
}

train.data <- split_date(train.data)
```



Adding new column, temp.div <- temp / atemp

```{r temp_diff}
train.data <- train.data %>%
    mutate(temp.div = temp / atemp)
```

Adding new column, day.type -- 1.holiday, 2.working day or 3.weekend

```{r day_type}
train.data <- train.data %>%
    mutate(day.type = NA, day.type.name = NA)

day_type <- function(df){
    df[['day.type']] <- ifelse(df[['holiday']] == 1, 1,
                               ifelse(df[['workingday']] == 1, 2, 
                                      3))
    df[['day.type.name']] <- ifelse(df[['day.type']] == 1, 'Holiday',
                               ifelse(df[['day.type']] == 2, 'Workingday', 
                                      'Weekend'))
    return(df)
}

train.data <- day_type(train.data) %>% select(-holiday, -workingday)
```

Now lets check the data again

```{r pre_process_end}
summary(train.data)
```

## Data Exploration
First lets check the proportion of casual to registered users
```{r explore_start}
train.data %>% mutate(casual.count = sum(casual),
                      registered.count = sum(registered)) %>%
    select(casual.count, registered.count) %>%
    distinct() %>%
    gather(key = user.type, value = user.count, 
           casual.count:registered.count) %>%
    mutate(user.prop = user.count / sum(user.count))
    
```

### No. of Users by different measures of DateTime (Before Binning)

```{r explore0, fig.height=5, fig.width=10, fig.align='center'}
count_x_time_plot <- function(df){
    
    g1 <- ggplot(data = df, mapping = aes(x = year, y = count/1000)) + 
                        geom_bar(stat = 'identity')
    g2 <- ggplot(data = df, mapping = aes(x = month.name, y = count/1000)) + 
                        geom_bar(stat = 'identity')
    g3 <- ggplot(data = df, mapping = aes(x = week.day.name, y = count/1000)) + 
                        geom_bar(stat = 'identity')
    g4 <- ggplot(data = df, mapping = aes(x = hour, y = count/1000)) + 
                        geom_bar(stat = 'identity')
    
    grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)
}

count_x_time_plot(train.data)
```


### No. of Users by Season & Weather
Lets check the effect of seasons and weather on the users

```{r explore1, fig.height=4, fig.width=8, fig.align='center'}
train.data %>% 
    select(season.name, weather.type, count) %>% 
    group_by(season.name, weather.type) %>%
    mutate(user.count = sum(count)) %>%
    distinct(season.name, weather.type,user.count) %>%
    ggplot(mapping = aes(season.name, user.count, fill = weather.type)) +
    geom_bar(stat = 'identity', width = 0.7) +
    scale_y_continuous(labels = comma) +
    coord_flip() +
    ggtitle('No. of Users by Season & Weather')

```

It seems less people ride bicycles during Spring season than other seasons.

Most people ride during good weather (Clear, Partly Cloudy). Only the most dedicated ride in bad weather (Thunderstorm, Light snow or Rain).


### Usage pattern over Days of Week & Hours of Day
Lets check user count over days of week

```{r explore2, fig.height=5, fig.width=8, fig.align='center'}
train.data %>%
    mutate(week.day.name = as.factor(week.day.name), 
           day.hour = as.factor(day.hour)) %>%
    select(week.day.name, day.hour, count) %>%
    group_by(week.day.name, day.hour) %>%
    mutate(user.count = sum(count)) %>%
    distinct(week.day.name, day.hour, user.count) %>%
    ggplot(mapping = aes(x = week.day.name, y = user.count/1000, 
                         fill = day.hour)) +
    geom_bar(stat = 'identity') +
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'Usage pattern over Days of Week & Hours of Day', 
            subtitle = '(User count is in thousands)')

```

The overall user count remains almost same for all 7 day of the week. But clear patterns can be seen for hourly usage on weekdays vs weekends. 

On weekdays the office travel time (7 AM - 10 AM and 6 PM - 9 PM) has most traffic. 

On weekends the 11 AM to 5 PM time has most traffic.

### No. of Users based on Hour of Day over the Years
Lets check what time of the day most users ride.

```{r explore4, fig.height=8, fig.width=10, fig.align='center'}
train.data %>%
    select(day.hour, date.year, count) %>%
    group_by(day.hour, date.year) %>%
    mutate(user.count = sum(count)) %>%
    distinct(day.hour, date.year, user.count) %>%
    ggplot(mapping = aes(x = day.hour, y = user.count/1000)) +
    geom_bar(stat = 'identity') +
    facet_wrap(~ date.year, nrow = 2) + 
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'No. of Users by Hour of Day', 
            subtitle = '(User count is in thousands)')

```

As expected, most users ride between 6 AM to 11 PM. The bicycle use peaks at 8 AM and between 4 PM to 7 PM. 

There is a consistent level of bicycle use from 7 AM to 8 PM, with only a slight dip at 10 AM. After 8 PM, the usage slowly decreases.


### Correlaton between features and User count

Lets see the correlation between numeric features and User count.

```{r explore6, fig.align='center', fig.height=6, fig.width=6}
train.data %>%
    select(c(2:7, 13:17, 20:21)) %>%
    distinct() %>% cor() %>% round(digits = 1) %>%
    ggcorrplot(method = 'circle', 
               type = 'full', hc.order = T, lab = T, lab_size = 3, 
               ggtheme = theme_bw, 
               title = 'Correlaton between features and User count')

```

User Count seems to have positive correlation to Temperature and negative to humidity.

## Model Training, Prediction & Evaluation - 1

We will use Linear Model, Decision Tree(RPart) & Random Forest to train our models.

First we will Configure parallel processing

```{r parallel_cluster}
ncluster <- makeCluster(detectCores() - 1)
registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split}
# set.seed(777)
# 
# sample.train.data <- sample_n(train.data, size = 2000)
#     
# inTraining <- createDataPartition(y = sample.train.data$count, 
#                                   p = 0.75, list = F)
# training <- sample.train.data[inTraining, ]
# testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split}
set.seed(777)

inTraining <- createDataPartition(y = train.data$count,
                                  p = 0.75, list = F)
training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features}
feature.list <- c(2:7, 13:17, 20:21)
```


Setting train control and grid parameters

```{r train_control}
tr.ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5,
                        verboseIter = T, allowParallel = T)

grid.rf <- expand.grid(.mtry = c(2, 4, 8, 13))
```

Training models

```{r train_model1, message=FALSE, warning=FALSE }
set.seed(777)
fit.lm.casual <- train(x = training[feature.list], y = training$casual, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.lm.reg <- train(x = training[feature.list], y = training$registered, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.lm.count <- train(x = training[feature.list], y = training$count, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

```

```{r train_model2, message=FALSE, warning=FALSE }
set.seed(777)
fit.rpart.casual <- train(x = training[feature.list], y = training$casual, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.rpart.reg <- train(x = training[feature.list], y = training$registered, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.rpart.count <- train(x = training[feature.list], y = training$count, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)
```

```{r train_model3, message=FALSE, warning=FALSE }
set.seed(777)
fit.rf.casual <- train(x = training[feature.list], y = training$casual, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.reg <- train(x = training[feature.list], y = training$registered, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.count <- train(x = training[feature.list], y = training$count, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the models

```{r model_evaluation}
resamps <- resamples(list(LM.cas = fit.lm.casual,
                          LM.reg = fit.lm.reg,
                          LM.count = fit.lm.count, 
                          RPART.cas = fit.rpart.casual,
                          RPART.reg = fit.rpart.reg,
                          RPART.count = fit.rpart.count,
                          RF.cas = fit.rf.casual,
                          RF.reg = fit.rf.reg,
                          RF.count = fit.rf.count))
summary(resamps)
```

Random Forest is clearly the best performer.

Variable Importance

```{r variable_importance1}
varImp(object = fit.rf.casual, scale = T)
```

```{r variable_importance2}
varImp(object = fit.rf.reg, scale = T)
```

```{r variable_importance3}
varImp(object = fit.rf.count, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop}
stopCluster(ncluster)
registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict}
predict.rf.casual <- predict(fit.rf.casual, newdata = testing[feature.list])
predict.rf.reg <- predict(fit.rf.reg, newdata = testing[feature.list])
predict.rf.count <- predict(fit.rf.count, newdata = testing[feature.list])
predict.rf.count.add <- predict.rf.casual + predict.rf.reg
```

Lets evaluate our model

```{r rmse}
RMSE(pred = predict.rf.count, obs = testing$count)
```

```{r rmse2}
RMSE(pred = predict.rf.count.add, obs = testing$count)
```

## Model Training, Prediction & Evaluation - 2

This time we will remove Features having least variable importance for each model and see if it improves our models.

First we will Configure parallel processing

```{r parallel_cluster_2}
ncluster <- makeCluster(detectCores() - 1)
registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split_2}
# set.seed(777)
# 
# sample.train.data <- sample_n(train.data, size = 2000)
#     
# inTraining <- createDataPartition(y = sample.train.data$count, 
#                                   p = 0.75, list = F)
# training <- sample.train.data[inTraining, ]
# testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split_2}
set.seed(777)

inTraining <- createDataPartition(y = train.data$count,
                                  p = 0.75, list = F)
training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features_2}
feature.list.casual2 <- c(2:7, 13:15, 17, 20:21)
feature.list.reg2 <- c(2:6, 13:17, 20:21)
feature.list.count2 <- c(2:6, 13:17, 20:21)
```


Setting train control and grid parameters

```{r train_control_2}
tr.ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5,
                        verboseIter = T, allowParallel = T)

grid.rf <- expand.grid(.mtry = c(6, 8, 10, 12))
```

Training model

```{r train_model_2, message=FALSE, warning=FALSE }
set.seed(777)
fit.rf.casual2 <- train(x = training[feature.list.casual2], y = training$casual, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.reg2 <- train(x = training[feature.list.reg2], y = training$registered, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.count2 <- train(x = training[feature.list.count2], y = training$count, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the model

```{r model_evaluation_2}
resamps <- resamples(list(RF.Casual1 = fit.rf.casual, 
                          RF.Casual2 = fit.rf.casual2,
                          RF.Reg1 = fit.rf.reg,
                          RF.Reg2 = fit.rf.reg2,
                          RF.Count = fit.rf.count,
                          RF.Count2 = fit.rf.count2))
summary(resamps)
```

By removing the weaker features, the model has improved (except casual).

Variable Importance

```{r variable_importance1_2}
varImp(object = fit.rf.casual2, scale = T)
```

```{r variable_importance2_2}
varImp(object = fit.rf.reg2, scale = T)
```

```{r variable_importance3_2}
varImp(object = fit.rf.count2, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop_2}
stopCluster(ncluster)
registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict_2}
predict.rf.casual2 <- predict(fit.rf.casual2, 
                              newdata = testing[feature.list.casual2])
predict.rf.reg2 <- predict(fit.rf.reg2, 
                           newdata = testing[feature.list.reg2])
predict.rf.count2 <- predict(fit.rf.count2, 
                             newdata = testing[feature.list.count2])
predict.rf.count.add2 <- predict.rf.casual2 + predict.rf.reg2
```

Lets evaluate our model

```{r rmse_2}
RMSE(pred = predict.rf.count2, obs = testing$count)
```

```{r rmse2_2}
RMSE(pred = predict.rf.count.add2, obs = testing$count)
```

Looks like calculating Casual and Registered users separately and then adding them to get count gives better result.

## Model Training, Prediction & Evaluation - 3

This time we will try tuning the addition model further and see if it improves our model.

First we will Configure parallel processing.

```{r parallel_cluster_3}
ncluster <- makeCluster(detectCores() - 1)
registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split_3}
# set.seed(777)
# 
# sample.train.data <- sample_n(train.data, size = 2000)
#     
# inTraining <- createDataPartition(y = sample.train.data$count, 
#                                   p = 0.75, list = F)
# training <- sample.train.data[inTraining, ]
# testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split_3}
set.seed(777)

inTraining <- createDataPartition(y = train.data$count,
                                  p = 0.75, list = F)
training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features_3}
feature.list.casual3 <- c(2:7, 13:15, 17, 20:21)
feature.list.reg3 <- c(2:6, 13:17, 20:21)
```


Setting train control and grid parameters

```{r train_control_3}
tr.ctrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 10,
                        verboseIter = T, allowParallel = T)

grid.rf <- expand.grid(.mtry = c(4, 6, 8))
```

Training model

```{r train_model_3, message=FALSE, warning=FALSE }
set.seed(777)
fit.rf.casual3 <- train(x = training[feature.list.casual3], y = training$casual,
                method = 'rf', metric = 'RMSE', importance = T, verbose = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.reg3 <- train(x = training[feature.list.reg3], y = training$registered,
                method = 'rf', metric = 'RMSE', importance = T, verbose = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the model

```{r model_evaluation_3}
resamps1 <- resamples(list(RF.Casual2 = fit.rf.casual2,
                          RF.Reg3 = fit.rf.reg2))
summary(resamps1)
```

```{r model_evaluation_3_2}
resamps2 <- resamples(list(RF.Casual3 = fit.rf.casual3,
                          RF.Reg3 = fit.rf.reg3))
summary(resamps2)
```

Variable Importance

```{r variable_importance1_3}
varImp(object = fit.rf.casual3, scale = T)
```

```{r variable_importance2_3}
varImp(object = fit.rf.reg3, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop_3}
stopCluster(ncluster)
registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict_3}
predict.rf.casual3 <- predict(fit.rf.casual3,
                              newdata = testing[feature.list.casual3])
predict.rf.reg3 <- predict(fit.rf.reg3,
                           newdata = testing[feature.list.reg3])
predict.rf.count.add3 <- predict.rf.casual3 + predict.rf.reg3
```


```{r rmse2_3}
RMSE(pred = predict.rf.count.add3, obs = testing$count)
```

Higher crossvalidation did not decrease the RMSE.

## Final Prediction & Submission

We will use model-2 to create our submission.

We need to apply the same pre-processing steps to Test data as we did with Train data.

Splitting datetime into year, month, day_num, day_name, hour

```{r split_date_test}
test.data <- split_date(test.data)
```

To avoid Infinite values in temp.div, we will replace atemp = 0 with atemp = 1.

```{r remove_Inf}
test.data$atemp <- plyr::mapvalues(x = test.data$atemp, 
                                   from = 0, to = 1)
```

Adding new column, temp.div <- temp / atemp

```{r temp_div_test}
test.data <- test.data %>%
   mutate(temp.div = temp / atemp)
```

Adding new column, day.type -- working day, holiday or weekend

```{r day_type_test}
test.data <- day_type(test.data) %>% select(-holiday, -workingday)
```

Now that pre-processing the test data is complete, lets run the predict the output.

First, creating feature list for test data

```{r features_test}
feature.list.casual.test <- c(2:9, 11, 14:16)
feature.list.reg.test <- c(2:6, 8:9, 11:12, 14:16)
```

Making Prediction

```{r predict_test}
predict.rf.casual.test <- predict(fit.rf.casual2,
                              newdata = test.data[feature.list.casual.test])
predict.rf.reg.test <- predict(fit.rf.reg2,
                           newdata = test.data[feature.list.reg.test])

predict.rf.count.add.test <- predict.rf.casual.test + predict.rf.reg.test
```

Creating Submission Files

```{r Submission}
test.data$count <- predict.rf.count.add.test

test.data %>% select(datetime, count) %>%
    write.csv(file = './Output/submit_sample_count_add_mod2.csv',
              quote = F, row.names = F)
```
