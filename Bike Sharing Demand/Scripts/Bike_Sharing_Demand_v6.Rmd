---
title: "Bike Sharing Demand"
output: 
    html_notebook:
        author: Paresh Pradhan
        theme: readable
---

# Introduction
We have to predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.

We will use Caret package's Random Forest to model the data.

```{r start, message=FALSE, warning=FALSE}
require(plyr)
detach(package:plyr)
library(tidyverse)
library(lubridate)
library(broom)
library(caret)
library(scales)
library(ggcorrplot)
library(parallel)
library(doParallel)
library(gridExtra)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(mosaic)
```

# Trial-0

### Data Preparation

```{r t0_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Checking data:

```{r t0_check_data}
glimpse(train.data)
anyNA(train.data)
```

Splitting date:

```{r t0_split_date}

split_date <- function(df){
    df[['year']] = year(df[['datetime']])
    df[['month']] = month(df[['datetime']])
    df[['month.day']] = day(df[['datetime']])
    df[['week.day']] = wday(df[['datetime']])
    df[['hour']] = hour(df[['datetime']])
    df[['month.name']] = month(df[['datetime']], label = T)
    df[['week.day.name']] = wday(df[['datetime']], label = T)
    
    return(df)
}

train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t0_day_type}

day_type <- function(df){
    df[['day.type']] <- ifelse(df[['holiday']] == 1, 1,
                               ifelse(df[['workingday']] == 1, 2, 
                                      3))
    df[['day.type.name']] <- ifelse(df[['day.type']] == 1, 'Holiday',
                               ifelse(df[['day.type']] == 2, 'Workingday', 
                                      'Weekend'))
    return(df)
}

train.data <- day_type(train.data) %>% select(-holiday, -workingday)
test.data <- day_type(test.data) %>% select(-holiday, -workingday)
```

Converting to factors:

```{r t0_to_factor}
train.data[c(2:3, 11:19)] <- 
    lapply(X = train.data[c(2:3, 11:19)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))


test.data[c(2:3, 8:16)] <- 
    lapply(X = test.data[c(2:3, 8:16)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t0_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t0_feature_set}
# names(train.data)
feature.list <- c(2:7, 11:15, 18)
```

Creating training and testing splits

```{r t0_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t0_model_fit, results='hide'}
set.seed(777)
fit.rf.cas0 <- randomForest(x = training[feature.list], y = training$casual,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg0 <- randomForest(x = training[feature.list], y = training$registered,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t0_var_imp1}
tidy(fit.rf.cas0$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t0_var_imp2}
tidy(fit.rf.reg0$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t0_predict}
predict.rf.cas <- predict(fit.rf.cas0, newdata = testing[feature.list])
predict.rf.reg <- predict(fit.rf.reg0, newdata = testing[feature.list])
predict.rf.count <- predict.rf.casual + predict.rf.reg
```

Scoring the models:

```{r t0_model_eval1}
RMSE(pred = predict.rf.cas, obs = testing$casual)
```

```{r t0_model_eval2}
RMSE(pred = predict.rf.reg, obs = testing$registered)
```

### Error Discovery

Creating Error data:

```{r t0_error_data}
error.data <- testing %>%
    mutate(predict.cas = predict.rf.cas, 
           predict.reg = predict.rf.reg) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t0_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.casual)) +
    geom_point() +
    ggtitle('Error Plot - Casual')
```

```{r t0_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point() +
    ggtitle('Error Plot - Registered')
```

The highest error values are for low values for casual and registered. Lets expand the lower end by taking log of casual and registered.


# Trial-1

### Data Preparation

```{r t1_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t1_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t1_day_type}
train.data <- day_type(train.data) %>% select(-holiday, -workingday)
test.data <- day_type(test.data) %>% select(-holiday, -workingday)
```

Checking distributions of Casual and Registered:

```{r t1_dist1}
train.data %>%
    ggplot(mapping = aes(x = casual)) +
    geom_histogram(binwidth = 3) +
    ggtitle('Distribution - Casual')
```

```{r t1_dist2}
train.data %>%
    ggplot(mapping = aes(x = registered)) +
    geom_histogram(binwidth = 5) +
    ggtitle('Distribution - Registered')
```

Both are highly right skewed.

Adding log of casual and registered:

```{r t1_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Checking distributions after log transformation:

```{r t1_dist3}
train.data %>%
    ggplot(mapping = aes(x = log.cas)) +
    geom_density() +
    ggtitle('Distribution - LogCasual')
```

```{r t1_dist4}
train.data %>%
    ggplot(mapping = aes(x = log.reg)) +
    geom_density() +
    ggtitle('Distribution - LogRegistered')
```

These are more normalized.

Converting to factors:

```{r t1_to_factor}
train.data[c(2:3, 11:19)] <- 
    lapply(X = train.data[c(2:3, 11:19)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))


test.data[c(2:3, 8:16)] <- 
    lapply(X = test.data[c(2:3, 8:16)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t1_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t1_feature_set}
# names(train.data)
feature.list <- c(2:7, 11:15, 18)
```

Creating training and testing splits

```{r t1_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t1_model_fit, results='hide'}
set.seed(777)
fit.rf.cas1 <- randomForest(x = training[feature.list], y = training$log.cas,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg1 <- randomForest(x = training[feature.list], y = training$log.reg,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t1_var_imp1}
tidy(fit.rf.cas1$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t1_var_imp2}
tidy(fit.rf.reg1$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t1_predict}
predict.rf.cas <- predict(fit.rf.cas1, newdata = testing[feature.list])
predict.rf.reg <- predict(fit.rf.reg1, newdata = testing[feature.list])
predict.rf.count <- predict.rf.casual + predict.rf.reg
```

Scoring the models:

```{r t1_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t1_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```

The error increased slighty.

### Error Discovery

Creating Error data:

```{r t1_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t1_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.casual)) +
    geom_point() +
    ggtitle('Error Plot - Casual')
```

```{r t1_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point() +
    ggtitle('Error Plot - Registered')
```

Althought the RMSE increased and there is still high error at lower values, the error amount has decreased.

Lets check the effect of the variables on Error:

```{r t1_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t1_error_explore4, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

We are getting most of our error as follows:

Casual: Weekend - 10 PM to 8 AM
        Workingday - 9 PM to 6 AM
        Holidays - 3 PM to 7 AM
Registered: Weekend - 3 AM to 8 AM
            Workingday - 11 PM to 6 AM
            Holidays - 3 PM to 7 AM

Lets try individual features for each day type and grouping hour of day.

# Trial-2

### Data Preparation

```{r t2_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t2_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type (but keeping holiday and workingday variables):

```{r t2_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t2_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t2_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Using decision tree to divide the hours into separate groups for casual and registered:

```{r t2_dtree_hour_group}
dtree.hrgroup.cas <- rpart(log.cas ~ hour, data = train.data)
fancyRpartPlot(dtree.hrgroup.cas)
```

```{r t2_hour_group1}
hour_group_cas <- function(df){
    
    df[['hour.group.cas']] [df[['hour']] < 1.5] <- '0to1'
    df[['hour.group.cas']] [df[['hour']] >= 1.5 & df[['hour']] < 6.5] <- '2to6'
    df[['hour.group.cas']] [df[['hour']] >= 6.5 & df[['hour']] < 7.5] <- '7to7'
    df[['hour.group.cas']] [df[['hour']] >= 7.5 & df[['hour']] < 10] <- '8to9'
    df[['hour.group.cas']] [df[['hour']] >= 10 & df[['hour']] < 20] <- '10to19'
    df[['hour.group.cas']] [df[['hour']] >= 20] <- '20to23'
    
    return(df)
}

train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t2_dtree_hour_group2}
dtree.hrgroup.reg <- rpart(log.reg ~ hour, data = train.data)
fancyRpartPlot(dtree.hrgroup.reg)
```

```{r t2_hour_group2}
hour_group_reg <- function(df){
    
    df[['hour.group.reg']] [df[['hour']] < 1.5] <- '0to1'
    df[['hour.group.reg']] [df[['hour']] >= 1.5 & df[['hour']] < 5.5] <- '2to5'
    df[['hour.group.reg']] [df[['hour']] >= 5.5 & df[['hour']] < 6.5] <- '6to6'
    df[['hour.group.reg']] [df[['hour']] >= 6.5 & df[['hour']] < 16] <- '7to15'
    df[['hour.group.reg']] [df[['hour']] >= 16 & df[['hour']] < 20] <- '16to19'
    df[['hour.group.reg']] [df[['hour']] >= 20 & df[['hour']] < 22] <- '20to21'
    df[['hour.group.reg']] [df[['hour']] >= 22] <- '22to23'
    
    return(df)
}

train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```

```{r t2_hour_group3, echo=FALSE}
# train.data %>% select(hour, hour.group.cas, hour.group.reg) %>% distinct()
```

Converting to factors:

```{r t2_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:26)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:26)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:21)] <- 
    lapply(X = test.data[c(2:5, 10:21)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t2_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t2_feature_set}
# names(train.data)
feature.list.cas <- c(2, 5:9, 13:16, 20, 25)
feature.list.reg <- c(2, 5:9, 13:16, 20, 26)
```

Creating training and testing splits

```{r t2_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t2_model_fit, results='hide'}
set.seed(777)
fit.rf.cas2 <- randomForest(x = training[feature.list.cas], y = training$log.cas,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg2 <- randomForest(x = training[feature.list.reg], y = training$log.reg,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t2_var_imp1}
tidy(fit.rf.cas2$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t2_var_imp2}
tidy(fit.rf.reg2$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t2_predict}
predict.rf.cas <- predict(fit.rf.cas2, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg2, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t2_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t2_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```


### Error Discovery

Creating Error data:

```{r t2_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t2_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point() +
    ggtitle('Error Plot - Casual')
```

```{r t2_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point() +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t2_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t2_error_explore4, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t2_error_explore5}
error.data %>%
    select(temp, atemp, humidity, windspeed, log.cas, log.reg) %>%
    distinct() %>% cor() %>% round(digits = 1) %>%
    ggcorrplot(method = 'circle', type = 'full', lab_size = 3, lab = T, 
               hc.order = T)
```


```{r t2_error_explore6}
error.data %>% 
    ggplot(aes(x = windspeed, y = error.cas, col = hour.group.cas)) +
    geom_point(alpha = 1) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0)
```

```{r t2_error_explore7}
error.data %>% 
    ggplot(aes(x = windspeed, y = error.reg, col = hour.group.reg)) +
    geom_point(alpha = 1) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0)
```

```{r t2_error_explore8}
error.data %>% 
    ggplot(aes(x = humidity, y = error.cas, col = hour.group.cas)) +
    geom_point(alpha = 0.8) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0)
```

```{r t2_error_explore9}
error.data %>% 
    ggplot(aes(x = humidity, y = error.reg, col = hour.group.reg)) +
    geom_point(alpha = 0.8) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0)
```

Most of our error is in the 2-6 AM time period. But after checking out windspeed and humidity variables we see some error patterns:
1. Error increases as humidity increases.
2. Error increases as windspeed decreases.
3. 2-6 AM time period has both high humidity and low windspeed.


Lets try to create grouos for windspeed and humidity and see if it helps.

# Trial-3

### Data Preparation

```{r t3_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t3_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t3_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t3_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t3_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Dividing hour into separate groups for casual and registered:

```{r t3_hour_group1}
train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t3_hour_group2}
train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```

Checking the distributions of Humidity and Windspeed:

```{r t3_dist1}
train.data %>% ggplot(aes(x = humidity)) + geom_density()
```

```{r t3_dist2}
train.data %>% ggplot(aes(x = windspeed)) + geom_density()
```

Using Decision trees to divide Humidity into groups for casual and registered.

```{r t2_dtree_hum_group1}
dtree.humgroup.cas <- rpart(log.cas ~ humidity, data = train.data)
fancyRpartPlot(dtree.humgroup.cas)
```

```{r t3_humidity_group1}
hum_group_cas <- function(df){
    
    df[['hum.group.cas']] [df[['humidity']] < 46] <- 'lt46'
    df[['hum.group.cas']] [df[['humidity']] >= 46 & 
                               df[['humidity']] < 74] <- '46to74'
    df[['hum.group.cas']] [df[['humidity']] >= 74 & 
                               df[['humidity']] < 84] <- '74to84'
    df[['hum.group.cas']] [df[['humidity']] >= 84] <- 'gt84'
    
    return(df)
}

train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```


```{r t2_dtree_hum_group2}
dtree.humgroup.reg <- rpart(log.reg ~ humidity, data = train.data)
fancyRpartPlot(dtree.humgroup.reg)
```

```{r t3_humidity_group2}
hum_group_reg <- function(df){
    
    df[['hum.group.reg']] [df[['humidity']] < 46] <- 'lt46'
    df[['hum.group.reg']] [df[['humidity']] >= 46 & 
                               df[['humidity']] < 62] <- '46to62'
    df[['hum.group.reg']] [df[['humidity']] >= 62 & 
                               df[['humidity']] < 84] <- '62to84'
    df[['hum.group.reg']] [df[['humidity']] >= 84] <- 'gt84'
    
    return(df)
}

train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t3_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Using Decision trees to divide Windspeed into groups for casual and registered.

```{r t3_dtree_wind_group1}
dtree.windgroup.cas <- rpart(log.cas ~ windspeed, data = train.data, 
                             control = rpart.control(cp = 0.0005))
fancyRpartPlot(dtree.windgroup.cas)
```

```{r t3_wind_group1}
wind_group_cas <- function(df){
    
    df[['wind.group.cas']] [df[['windspeed']] < 1 ] <- 'lt1'
    df[['wind.group.cas']] [df[['windspeed']] >= 1 & 
                               df[['windspeed']] < 6.5] <- '1to6.5'
    df[['wind.group.cas']] [df[['windspeed']] >= 6.5 & 
                               df[['windspeed']] < 10] <- '6.5to10'
    df[['wind.group.cas']] [df[['windspeed']] >= 10 & 
                               df[['windspeed']] < 14] <- '10to14'
    df[['wind.group.cas']] [df[['windspeed']] >= 14] <- 'gt14'
    
    return(df)
}

train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```


```{r t3_dtree_wind_group2}
dtree.windgroup.reg <- rpart(log.reg ~ windspeed, data = train.data, 
                             control = rpart.control(cp = 0.001))
fancyRpartPlot(dtree.windgroup.reg)
```

```{r t3_wind_group2}
wind_group_reg <- function(df){
    
    df[['wind.group.reg']] [df[['windspeed']] < 1 ] <- 'lt1'
    df[['wind.group.reg']] [df[['windspeed']] >= 1 & 
                               df[['windspeed']] < 6.5] <- '1to6.5'
    df[['wind.group.reg']] [df[['windspeed']] >= 6.5 & 
                               df[['windspeed']] < 10] <- '6.5to10'
    df[['wind.group.reg']] [df[['windspeed']] >= 10 & 
                               df[['windspeed']] < 14] <- '10to14'
    df[['wind.group.reg']] [df[['windspeed']] >= 14] <- 'gt14'
    
    return(df)
}

train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t3_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Converting to factors:

```{r t3_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:30)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:30)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:25)] <- 
    lapply(X = test.data[c(2:5, 10:25)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t3_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t3_feature_set}
# names(train.data)
feature.list.cas <- c(2, 5:7, 13:16, 20, 25, 27, 29)
feature.list.reg <- c(2, 5:7, 13:16, 20, 26, 28, 30)
```

Creating training and testing splits

```{r t3_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t3_model_fit, results='hide'}
set.seed(777)
fit.rf.cas3 <- randomForest(x = training[feature.list.cas], y = training$log.cas,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg3 <- randomForest(x = training[feature.list.reg], y = training$log.reg,
                               ntree = 500, mtry = c(3, 6, 12), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t3_var_imp1}
tidy(fit.rf.cas3$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t3_var_imp2}
tidy(fit.rf.reg3$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t3_predict}
predict.rf.cas <- predict(fit.rf.cas3, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg3, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t3_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t3_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```


### Error Discovery

Creating Error data:

```{r t3_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t3_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point() +
    ggtitle('Error Plot - Casual')
```

```{r t3_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point() +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t3_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t3_error_explore4, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```


There is no obvious improvement. Lets try to remove the weker variables - wether and windspeed.

# Trial-4

### Data Preparation

```{r t4_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t4_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t4_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t4_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t4_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Dividing hour into separate groups for casual and registered:

```{r t4_hour_group1}
train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t4_hour_group2}
train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```


Dividing humidity into separate groups for casual and registered:

```{r t4_humidity_group1}
train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```

```{r t4_humidity_group2}
train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t4_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Dividing windspeed into separate groups for casual and registered:

```{r t4_wind_group1}
train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```

```{r t4_wind_group2}
train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t4_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Converting to factors:

```{r t4_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:30)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:30)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:25)] <- 
    lapply(X = test.data[c(2:5, 10:25)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t4_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t4_feature_set}
# names(train.data)
feature.list.cas <- c(2, 6:8, 13:16, 20, 25, 27)
feature.list.reg <- c(2, 6:8, 13:16, 20, 26, 28)
```

Creating training and testing splits

```{r t4_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t4_model_fit, results='hide'}
set.seed(777)
fit.rf.cas4 <- randomForest(x = training[feature.list.cas], y = training$log.cas,
                               ntree = 500, mtry = c(3, 6, 9), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg4 <- randomForest(x = training[feature.list.reg], y = training$log.reg,
                               ntree = 500, mtry = c(3, 6, 9), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t4_var_imp1}
tidy(fit.rf.cas4$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t4_var_imp2}
tidy(fit.rf.reg4$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t4_predict}
predict.rf.cas <- predict(fit.rf.cas4, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg4, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t4_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t4_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```


### Error Discovery

Creating Error data:

```{r t4_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t4_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Casual')
```

```{r t4_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t4_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name + month.day)
```

```{r t4_error_explore4, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name + month)
```

Still not much improvement.  Lets try adding some new features.

# Trial-5

### Data Preparation

```{r t5_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t5_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t5_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t5_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t5_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Dividing hour into separate groups for casual and registered:

```{r t5_hour_group1}
train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t5_hour_group2}
train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```


Dividing humidity into separate groups for casual and registered:

```{r t5_humidity_group1}
train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```

```{r t5_humidity_group2}
train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t5_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Dividing windspeed into separate groups for casual and registered:

```{r t5_wind_group1}
train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```

```{r t5_wind_group2}
train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t5_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Dividing atemp into separate groups for casual and registered:

```{r t5_dtree_atemp_group1}
dtree.atemp.grp.cas <- rpart(log.cas ~ atemp, data = train.data)
fancyRpartPlot(dtree.atemp.grp.cas)
```

```{r t5_atemp_group1}
atemp_group_cas <- function(df){
    
    df[['atemp.group.cas']] [df[['atemp']] < 15] <- 'lt15'
    df[['atemp.group.cas']] [df[['atemp']] >= 15 & 
                               df[['atemp']] < 19] <- '15to19'
    df[['atemp.group.cas']] [df[['atemp']] >= 19 & 
                               df[['atemp']] < 30] <- '19to30'
    df[['atemp.group.cas']] [df[['atemp']] >= 30] <- 'gt30'
    
    return(df)
}

train.data <- atemp_group_cas(train.data)
test.data <- atemp_group_cas(test.data)
```

```{r t5_dtree_atemp_group2}
dtree.atemp.grp.reg <- rpart(log.reg ~ atemp, data = train.data)
fancyRpartPlot(dtree.atemp.grp.reg)
```

```{r t5_atemp_group2}
atemp_group_reg <- function(df){
    
    df[['atemp.group.reg']] [df[['atemp']] < 14] <- 'lt14'
    df[['atemp.group.reg']] [df[['atemp']] >= 14 & 
                               df[['atemp']] < 30] <- '14to30'
    df[['atemp.group.reg']] [df[['atemp']] >= 30] <- 'gt30'
    
    return(df)
}

train.data <- atemp_group_reg(train.data)
test.data <- atemp_group_reg(test.data)
```

```{r t5_atemp_group3}
# train.data %>% select(atemp, atemp.group.cas, atemp.group.reg) %>%
#     distinct() %>% arrange(atemp)
```


Adding new features:

```{r t5_new_features}
train.data$z.humidity2 <- zscore(train.data$humidity^2)
train.data$z.windspeed0.5 <- zscore(sqrt(train.data$windspeed))
train.data$hourgrp.daytype.cas <- paste(train.data$hour.group.cas, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.daytype.reg <- paste(train.data$hour.group.reg, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.atemp.cas <- paste(train.data$hour.group.cas, 
                                        train.data$atemp.group.cas, sep = ':')
train.data$hourgrp.atemp.reg <- paste(train.data$hour.group.reg, 
                                        train.data$atemp.group.reg, sep = ':')

test.data$z.humidity2 <- zscore(test.data$humidity^2)
test.data$z.windspeed0.5 <- zscore(sqrt(test.data$windspeed))
test.data$hourgrp.daytype.cas <- paste(test.data$hour.group.cas, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.daytype.reg <- paste(test.data$hour.group.reg, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.atemp.cas <- paste(test.data$hour.group.cas, 
                                   test.data$atemp.group.cas, sep = ':')
test.data$hourgrp.atemp.reg <- paste(test.data$hour.group.reg, 
                                   test.data$atemp.group.reg, sep = ':')
```


Converting to factors:

```{r t5_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:30, 33:38)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:30, 33:38)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:25, 28:33)] <- 
    lapply(X = test.data[c(2:5, 10:25, 28:33)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t5_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t5_feature_set}
# names(train.data)
feature.list.cas <- c(2, 6:7, 13:16, 20, 25, 27, 31:32, 33, 35, 37)
feature.list.reg <- c(2, 6:7, 13:16, 20, 26, 28, 31:32, 34, 36, 38)
# length(feature.list.cas)
```

Creating training and testing splits

```{r t5_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t5_model_fit, results='hide'}
set.seed(777)
fit.rf.cas5 <- randomForest(x = training[feature.list.cas], y = training$log.cas,
                               ntree = 500, mtry = c(4, 8, 15), importance = T,
                               do.trace = T)
set.seed(777)
fit.rf.reg5 <- randomForest(x = training[feature.list.reg], y = training$log.reg,
                               ntree = 500, mtry = c(4, 8, 15), importance = T,
                               do.trace = T)
```

### Model Evaluation

feature importance:

```{r t5_var_imp1}
tidy(fit.rf.cas5$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t5_var_imp2}
tidy(fit.rf.reg5$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t5_predict}
predict.rf.cas <- predict(fit.rf.cas5, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg5, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t5_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t5_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```


### Error Discovery

Creating Error data:

```{r t5_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t5_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Casual')
```

```{r t5_error_explore2}
error.data %>% 
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t5_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hourgrp.daytype.cas, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ month.name)
```

```{r t5_error_explore4, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ month)
```

Only slight improvement. Lets try removing features.

# Trial-6

### Data Preparation

```{r t6_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t6_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t6_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t6_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t6_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Dividing hour into separate groups for casual and registered:

```{r t6_hour_group1}
train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t6_hour_group2}
train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```


Dividing humidity into separate groups for casual and registered:

```{r t6_humidity_group1}
train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```

```{r t6_humidity_group2}
train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t6_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Dividing windspeed into separate groups for casual and registered:

```{r t6_wind_group1}
train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```

```{r t6_wind_group2}
train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t6_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Dividing atemp into separate groups for casual and registered:

```{r t6_atemp_group1}
train.data <- atemp_group_cas(train.data)
test.data <- atemp_group_cas(test.data)
```

```{r t6_atemp_group2}
train.data <- atemp_group_reg(train.data)
test.data <- atemp_group_reg(test.data)
```

```{r t6_atemp_group3}
# train.data %>% select(atemp, atemp.group.cas, atemp.group.reg) %>%
#     distinct() %>% arrange(atemp)
```


Adding new features:

```{r t6_new_features}
train.data$z.humidity2 <- zscore(train.data$humidity^2)
train.data$z.windspeed0.5 <- zscore(sqrt(train.data$windspeed))
train.data$hourgrp.daytype.cas <- paste(train.data$hour.group.cas, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.daytype.reg <- paste(train.data$hour.group.reg, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.atemp.cas <- paste(train.data$hour.group.cas, 
                                        train.data$atemp.group.cas, sep = ':')
train.data$hourgrp.atemp.reg <- paste(train.data$hour.group.reg, 
                                        train.data$atemp.group.reg, sep = ':')

test.data$z.humidity2 <- zscore(test.data$humidity^2)
test.data$z.windspeed0.5 <- zscore(sqrt(test.data$windspeed))
test.data$hourgrp.daytype.cas <- paste(test.data$hour.group.cas, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.daytype.reg <- paste(test.data$hour.group.reg, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.atemp.cas <- paste(test.data$hour.group.cas, 
                                   test.data$atemp.group.cas, sep = ':')
test.data$hourgrp.atemp.reg <- paste(test.data$hour.group.reg, 
                                   test.data$atemp.group.reg, sep = ':')
```


Converting to factors:

```{r t6_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:32, 35:38)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:32, 35:38)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:27, 30:33)] <- 
    lapply(X = test.data[c(2:5, 10:27, 30:33)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t6_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t6_feature_set}
names(train.data)
feature.list.cas <- c(2, 4:9, 13:18, 20, 22, 25, 27, 31, 35, 37)
feature.list.reg <- c(2, 4:7, 13, 16:18, 20, 22, 26, 32, 33, 36, 38)
length(feature.list.cas)
length(feature.list.reg)
```

Creating training and testing splits

```{r t6_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Fitting Models:

```{r t6_model_fit, results='hide'}
set.seed(777)
fit.rf.cas6 <- randomForest(x = training[feature.list.cas], y = training$log.cas,
                            ntree = 1000, mtry = c(2, 4, 8, 20), 
                            importance = T, do.trace = T)
set.seed(777)
fit.rf.reg6 <- randomForest(x = training[feature.list.reg], y = training$log.reg,
                            ntree = 1000, mtry = c(2, 4, 8, 16), 
                            importance = T, do.trace = T)
```

### Model Evaluation

feature importance:

```{r t6_var_imp1}
tidy(fit.rf.cas6$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t6_var_imp2}
tidy(fit.rf.reg6$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t6_predict}
predict.rf.cas <- predict(fit.rf.cas6, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg6, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t6_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t6_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```

```{r t6_model_eval3}
RMSE(pred = expm1(predict.rf.cas) + expm1(predict.rf.reg) , 
     obs = testing$count)
```

### Error Discovery

Creating Error data:

```{r t6_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t6_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Casual')
```

```{r t6_error_explore2}
error.data %>% filter(error.reg < 500) %>%
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t6_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t6_error_explore4, fig.height=6, fig.width=12}
error.data %>% filter(error.reg < 500) %>%
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

Finally, Some improvement. Lets put it into cross-validation.

# Trial-7

### Data Preparation

```{r t7_read_data}
train.data <- tbl_df(read.csv('../Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('../Input/test.csv', stringsAsFactors = F))
```

Splitting date:

```{r t7_split_date}
train.data <- split_date(train.data)
test.data <- split_date(test.data)
```

Combining holiday and workingday into day.type:

```{r t7_day_type}
train.data <- day_type(train.data)
test.data <- day_type(test.data)
```

```{r t7_weekend}
train.data$weekend <- ifelse(train.data$day.type == 3, 1, 0)
test.data$weekend <- ifelse(test.data$day.type == 3, 1, 0)
```

Adding log of casual and registered to reduce skewness:

```{r t7_log_conv}
train.data$log.cas <- log(train.data$casual + 1)
train.data$log.reg <- log(train.data$registered + 1)
```

Dividing hour into separate groups for casual and registered:

```{r t7_hour_group1}
train.data <- hour_group_cas(train.data)
test.data <- hour_group_cas(test.data)
```

```{r t7_hour_group2}
train.data <- hour_group_reg(train.data)
test.data <- hour_group_reg(test.data)
```


Dividing humidity into separate groups for casual and registered:

```{r t7_humidity_group1}
train.data <- hum_group_cas(train.data)
test.data <- hum_group_cas(test.data)
```

```{r t7_humidity_group2}
train.data <- hum_group_reg(train.data)
test.data <- hum_group_reg(test.data)
```

```{r t7_humidity_group3, include=FALSE}
# train.data %>% select(humidity, hum.group.cas, hum.group.reg) %>% 
#     distinct() %>% arrange(humidity)
```


Dividing windspeed into separate groups for casual and registered:

```{r t7_wind_group1}
train.data <- wind_group_cas(train.data)
test.data <- wind_group_cas(test.data)
```

```{r t7_wind_group2}
train.data <- wind_group_reg(train.data)
test.data <- wind_group_reg(test.data)
```

```{r t7_wind_group3, include=FALSE}
# train.data %>% select(windspeed, wind.group.cas, wind.group.reg) %>%
#     distinct() %>% arrange(windspeed)
```

Dividing atemp into separate groups for casual and registered:

```{r t7_atemp_group1}
train.data <- atemp_group_cas(train.data)
test.data <- atemp_group_cas(test.data)
```

```{r t7_atemp_group2}
train.data <- atemp_group_reg(train.data)
test.data <- atemp_group_reg(test.data)
```

```{r t7_atemp_group3}
# train.data %>% select(atemp, atemp.group.cas, atemp.group.reg) %>%
#     distinct() %>% arrange(atemp)
```


Adding new features:

```{r t7_new_features}
train.data$z.humidity2 <- zscore(train.data$humidity^2)
train.data$z.windspeed0.5 <- zscore(sqrt(train.data$windspeed))
train.data$hourgrp.daytype.cas <- paste(train.data$hour.group.cas, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.daytype.reg <- paste(train.data$hour.group.reg, 
                                        train.data$day.type, sep = ':')
train.data$hourgrp.atemp.cas <- paste(train.data$hour.group.cas, 
                                        train.data$atemp.group.cas, sep = ':')
train.data$hourgrp.atemp.reg <- paste(train.data$hour.group.reg, 
                                        train.data$atemp.group.reg, sep = ':')

test.data$z.humidity2 <- zscore(test.data$humidity^2)
test.data$z.windspeed0.5 <- zscore(sqrt(test.data$windspeed))
test.data$hourgrp.daytype.cas <- paste(test.data$hour.group.cas, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.daytype.reg <- paste(test.data$hour.group.reg, 
                                   test.data$day.type, sep = ':')
test.data$hourgrp.atemp.cas <- paste(test.data$hour.group.cas, 
                                   test.data$atemp.group.cas, sep = ':')
test.data$hourgrp.atemp.reg <- paste(test.data$hour.group.reg, 
                                   test.data$atemp.group.reg, sep = ':')
```


Converting to factors:

```{r t7_to_factor}
# names(train.data)
train.data[c(2:5, 13:22, 25:32, 35:38)] <- 
    lapply(X = train.data[c(2:5, 13:22, 25:32, 35:38)], FUN = factor)
train.data$month.day <- factor(x = train.data$month.day, 
                               levels = as.character(1:31))

# names(test.data)
test.data[c(2:5, 10:27, 30:33)] <- 
    lapply(X = test.data[c(2:5, 10:27, 30:33)], FUN = factor)
test.data$month.day <- factor(x = test.data$month.day, 
                               levels = as.character(1:31))
```

```{r t7_check_data2}
glimpse(train.data)
```


### Model Fitting

Creating feature set:

```{r t7_feature_set}
names(train.data)
feature.list.cas <- c(2:9, 13:22, 25, 27, 29, 31, 33:34, 35, 37)
feature.list.reg <- c(2:9, 13:22, 26, 28, 30, 32, 33:34, 36, 38)
length(feature.list.cas)
length(feature.list.reg)
```

Creating training and testing splits

```{r t7_data_part}
set.seed(777)
inTraining <- createDataPartition(y = train.data$count, p = 0.75, list = F)

training <- train.data[inTraining, ]
testing <- train.data[-inTraining, ]
```

Control Parameters:

```{r t7_control_par}
tr.control <- trainControl(method = 'repeatedcv', number = 5, repeats = 5, 
                           verboseIter = T, allowParallel = T, p = 0.75)
tune.grid.cas <- expand.grid(mtry = c(2, 5, 10, 15, 26))
tune.grid.reg <- expand.grid(mtry = c(2, 5, 10, 15, 26))
```

Starting Cluster:

```{r t7_start_cluster}
# ncluster <- makeCluster(detectCores() - 1)
# registerDoParallel(ncluster)
```

Fitting Models:

```{r t7_model_fit, results='hide'}
set.seed(777)
fit.rf.cas7 <- train(x = training[feature.list.cas], y = training$log.cas, 
                     method = 'rf', metric = 'RMSE', #trControl = tr.control,  
                     tuneGrid = tune.grid.cas, importance = T, do.trace = T, 
                     ntree = 500)
set.seed(777)
fit.rf.reg7 <- train(x = training[feature.list.reg], y = training$log.reg, 
                     method = 'rf', metric = 'RMSE', #trControl = tr.control, 
                     tuneGrid = tune.grid.reg, importance = T, do.trace = T, 
                     ntree = 500)
```

DStopping cluster:

```{r t7_stop_cluster}
# stopCluster(ncluster)
# registerDoSEQ()
```

### Model Evaluation

feature importance:

```{r t7_var_imp1}
tidy(fit.rf.cas7$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

```{r t7_var_imp2}
tidy(fit.rf.reg7$importance) %>%
    mutate(importance = fmsb::percentile(X.IncMSE)) %>%
    select(.rownames, importance) %>%
    arrange(desc(importance))
```

Lets run the model on our testing split.

```{r t7_predict}
predict.rf.cas <- predict(fit.rf.cas7, newdata = testing[feature.list.cas])
predict.rf.reg <- predict(fit.rf.reg7, newdata = testing[feature.list.reg])
predict.rf.count <- predict.rf.cas + predict.rf.reg
```

Scoring the models:

```{r t7_model_eval1}
RMSE(pred = expm1(predict.rf.cas), obs = testing$casual)
```

```{r t7_model_eval2}
RMSE(pred = expm1(predict.rf.reg), obs = testing$registered)
```

```{r t7_model_eval3}
RMSE(pred = expm1(predict.rf.cas) + expm1(predict.rf.reg) , 
     obs = testing$count)
```

### Error Discovery

Creating Error data:

```{r t7_error_data}
error.data <- testing %>%
    mutate(predict.cas = expm1(predict.rf.cas), 
           predict.reg = expm1(predict.rf.reg)) %>%
    mutate(error.cas = ((predict.cas - casual) / (casual + 1)) * 100,
           error.reg = ((predict.reg - registered) / (registered + 1)) * 100)

```

Exploring Error data:

```{r t7_error_explore1}
error.data %>% 
    ggplot(aes(x = casual, y = error.cas)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Casual')
```

```{r t7_error_explore2}
error.data %>% filter(error.reg < 500) %>%
    ggplot(aes(x = registered, y = error.reg)) +
    geom_point(alpha = 0.3) +
    ggtitle('Error Plot - Registered')
```

Lets check the effect of the variables on Error:

```{r t7_error_explore3, fig.height=6, fig.width=12}
error.data %>% 
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.cas)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```

```{r t7_error_explore4, fig.height=6, fig.width=12}
error.data %>% filter(error.reg < 500) %>%
    mutate(hour = factor(hour, levels = as.character(0:23))) %>%
    ggplot(aes(x = hour, y = error.reg)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 50, slope = 0) +
    geom_abline(intercept = -50, slope = 0) +
    facet_wrap(~ day.type.name)
```


# Submission

Creating Submission Files

```{r Submission}
test.data$count <- predict.rf.count

test.data %>% select(datetime, count) %>%
    write.csv(file = '../Output/submit_count.csv',
              quote = F, row.names = F)
```


Saving Image:

```{r save_image}
save.image(file = "../RData_Files/Bike_Sharing_Demand_v6.RData")
```





