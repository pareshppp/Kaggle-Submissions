---
title: "Bike Sharing Demand"
output: 
    html_notebook:
        author: Paresh Pradhan
        theme: readable
---

## Introduction
We have to predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.

```{r start, message=FALSE, warning=FALSE}
require(plyr)
detach(package:plyr)
library(tidyverse)
library(lubridate)
library(broom)
library(caret)
library(scales)
library(ggcorrplot)
library(parallel)
library(doParallel)
```

```{r read_data}
train.data <- tbl_df(read.csv('./Input/train.csv', stringsAsFactors = F))
test.data <- tbl_df(read.csv('./Input/test.csv', stringsAsFactors = F))
```

## Data Pre-processing, Cleaning & Feature Extraction

```{r pre_process_start, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
str(train.data)
summary(train.data)
```

Adding season names.

```{r season_name}
season.list <- c('spring', 'summer', 'fall', 'winter')
train.data$season.name <- train.data$season

replace_season <- function(df){
    df[['season.name']] <- plyr::mapvalues(df[['season.name']], 
                                  from = c(1, 2, 3, 4), 
                                  to = season.list)
    return(df)
}

train.data <- replace_season(train.data)
```

Adding weather codes as follows:  
weather 1: clear_partly_cloudy
weather 2: mist_cloudy
weather 3: light_snow_rain_thunderstorm
weather 4: heavy_snow_rain_ice_fog_thunderstorm

```{r weather_type}
weather.list <- c('clear_partly_cloudy', 'mist_cloudy', 
                  'light_snow_rain_thunderstorm', 
                  'heavy_snow_rain_ice_fog_thunderstorm')

train.data$weather.type <- train.data$weather

replace_weather <- function(df){
    df[['weather.type']] <- plyr::mapvalues(df[['weather.type']], 
                                  from = c(1, 2, 3, 4), 
                                  to = weather.list)
    
    return(df)
}

train.data <- replace_weather(train.data)
```

Splitting datetime into year, month, day_num, day_name, hour

```{r split_date}
train.data <- train.data %>%
    mutate(date.year = 0, date.month = '', month.day = 0, 
           week.day = '', day.hour = 0)

split_date <- function(df){
    df[['date.year']] = year(df[['datetime']])
    df[['date.month']] = month(df[['datetime']])
    df[['date.month.name']] = month(df[['datetime']], label = T)
    df[['month.day']] = day(df[['datetime']])
    df[['week.day']] = wday(df[['datetime']])
    df[['week.day.name']] = wday(df[['datetime']], label = T)
    df[['day.hour']] = hour(df[['datetime']])
    
    return(df)
}

train.data <- split_date(train.data)
```

Adding new column, temp.div <- temp / atemp

```{r temp_diff}
train.data <- train.data %>%
    mutate(temp.div = temp / atemp)
```

Adding new column, day.type -- 1.holiday, 2.working day or 3.weekend

```{r day_type}
train.data <- train.data %>%
    mutate(day.type = NA, day.type.name = NA)

day_type <- function(df){
    df[['day.type']] <- ifelse(df[['holiday']] == 1, 1,
                               ifelse(df[['workingday']] == 1, 2, 
                                      3))
    df[['day.type.name']] <- ifelse(df[['day.type']] == 1, 'Holiday',
                               ifelse(df[['day.type']] == 2, 'Workingday', 
                                      'Weekend'))
    return(df)
}

train.data <- day_type(train.data) %>% select(-holiday, -workingday)
```

Now lets check the data again

```{r pre_process_end}
summary(train.data)
```

## Data Exploration
First lets check the proportion of casual to registered users
```{r explore_start}
train.data %>% mutate(casual.count = sum(casual),
                      registered.count = sum(registered)) %>%
    select(casual.count, registered.count) %>%
    distinct() %>%
    gather(key = user.type, value = user.count, 
           casual.count:registered.count) %>%
    mutate(user.prop = user.count / sum(user.count))
    
```

### No. of Users by Season & Weather
Lets check the effect of seasons and weather on the users

```{r explore1, fig.height=4, fig.width=8, fig.align='center'}
train.data %>% 
    select(season.name, weather.type, count) %>% 
    group_by(season.name, weather.type) %>%
    mutate(user.count = sum(count)) %>%
    distinct(season.name, weather.type,user.count) %>%
    ggplot(mapping = aes(season.name, user.count, fill = weather.type)) +
    geom_bar(stat = 'identity', width = 0.7) +
    scale_y_continuous(labels = comma) +
    coord_flip() +
    ggtitle('No. of Users by Season & Weather')

```

It seems less people ride bicycles during Spring season than other seasons.

Most people ride during good weather (Clear, Partly Cloudy). Only the most dedicated ride in bad weather (Thunderstorm, Light snow or Rain).


### Usage pattern over Days of Week & Hours of Day
Lets check user count over days of week

```{r explore2, fig.height=5, fig.width=8, fig.align='center'}
train.data %>%
    mutate(week.day.name = as.factor(week.day.name), 
           day.hour = as.factor(day.hour)) %>%
    select(week.day.name, day.hour, count) %>%
    group_by(week.day.name, day.hour) %>%
    mutate(user.count = sum(count)) %>%
    distinct(week.day.name, day.hour, user.count) %>%
    ggplot(mapping = aes(x = week.day.name, y = user.count/1000, 
                         fill = day.hour)) +
    geom_bar(stat = 'identity') +
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'Usage pattern over Days of Week & Hours of Day', 
            subtitle = '(User count is in thousands)')

```

The overall user count remains almost same for all 7 day of the week. But clear patterns can be seen for hourly usage on weekdays vs weekends. 

On weekdays the office travel time (7 AM - 10 AM and 6 PM - 9 PM) has most traffic. 

On weekends the 11 AM to 5 PM time has most traffic.

### No. of Users based on Hour of Day over the Years
Lets check what time of the day most users ride.

```{r explore4, fig.height=8, fig.width=10, fig.align='center'}
train.data %>%
    select(day.hour, date.year, count) %>%
    group_by(day.hour, date.year) %>%
    mutate(user.count = sum(count)) %>%
    distinct(day.hour, date.year, user.count) %>%
    ggplot(mapping = aes(x = day.hour, y = user.count/1000)) +
    geom_bar(stat = 'identity') +
    facet_wrap(~ date.year, nrow = 2) + 
    ylab('No. of users in 1000\'s') +
    ggtitle(label = 'No. of Users by Hour of Day', 
            subtitle = '(User count is in thousands)')

```

As expected, most users ride between 6 AM to 11 PM. The bicycle use peaks at 8 AM and between 4 PM to 7 PM. 

There is a consistent level of bicycle use from 7 AM to 8 PM, with only a slight dip at 10 AM. After 8 PM, the usage slowly decreases.


### Correlaton between features and User count

Lets see the correlation between numeric features and User count.

```{r explore6, fig.align='center', fig.height=6, fig.width=6}
train.data %>%
    select(c(2:7, 13:17, 20:21)) %>%
    distinct() %>% cor() %>% round(digits = 1) %>%
    ggcorrplot(method = 'circle', 
               type = 'full', hc.order = T, lab = T, lab_size = 3, 
               ggtheme = theme_bw, 
               title = 'Correlaton between features and User count')

```

User Count seems to have positive correlation to Temperature and negative to humidity.

## Model Training, Prediction & Evaluation - 1

We will use Linear Model, Decision Tree(RPart) & Random Forest to train our models.

First we will Configure parallel processing

```{r parallel_cluster}
ncluster <- makeCluster(detectCores() - 1)
registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split}
set.seed(777)

sample.train.data <- sample_n(train.data, size = 2000)
    
inTraining <- createDataPartition(y = sample.train.data$count, 
                                  p = 0.75, list = F)
training <- sample.train.data[inTraining, ]
testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split}
# set.seed(777)
# 
# inTraining <- createDataPartition(y = train.data$count, 
#                                   p = 0.75, list = F)
# training <- train.data[inTraining, ]
# testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features}
feature.list <- c(2:7, 13:17, 20:21)
```


Setting train control and grid parameters

```{r train_control}
tr.ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5,
                        verboseIter = T, allowParallel = T)

grid.rf <- expand.grid(.mtry = c(2, 4, 8, 13))
```

Training models

```{r train_model1, message=FALSE, warning=FALSE }
set.seed(777)
fit.lm.casual <- train(x = training[feature.list], y = training$casual, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.lm.reg <- train(x = training[feature.list], y = training$registered, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.lm.count <- train(x = training[feature.list], y = training$count, 
                       method = 'lm', metric = 'RMSE', trControl = tr.ctrl)

```

```{r train_model2, message=FALSE, warning=FALSE }
set.seed(777)
fit.rpart.casual <- train(x = training[feature.list], y = training$casual, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.rpart.reg <- train(x = training[feature.list], y = training$registered, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)

set.seed(777)
fit.rpart.count <- train(x = training[feature.list], y = training$count, 
                          method = 'rpart', metric = 'RMSE', trControl = tr.ctrl)
```

```{r train_model3, message=FALSE, warning=FALSE }
set.seed(777)
fit.rf.casual <- train(x = training[feature.list], y = training$casual, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.reg <- train(x = training[feature.list], y = training$registered, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.count <- train(x = training[feature.list], y = training$count, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the models

```{r model_evaluation}
resamps <- resamples(list(LM.cas = fit.lm.casual,
                          LM.reg = fit.lm.reg,
                          LM.count = fit.lm.count, 
                          RPART.cas = fit.rpart.casual,
                          RPART.reg = fit.rpart.reg,
                          RPART.count = fit.rpart.count,
                          RF.cas = fit.rf.casual,
                          RF.reg = fit.rf.reg,
                          RF.count = fit.rf.count))
summary(resamps)
```

Random Forest is clearly the best performer.

Variable Importance

```{r variable_importance1}
varImp(object = fit.rf.casual, scale = T)
```


```{r variable_importance2}
varImp(object = fit.rf.reg, scale = T)
```

```{r variable_importance3}
varImp(object = fit.rf.count, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop}
stopCluster(ncluster)
registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict}
predict.rf.casual <- predict(fit.rf.casual, newdata = testing[feature.list])
predict.rf.reg <- predict(fit.rf.reg, newdata = testing[feature.list])
predict.rf.count <- predict(fit.rf.count, newdata = testing[feature.list])
predict.rf.count.add <- predict.rf.casual + predict.rf.reg
```

Lets evaluate our model

```{r rmse}
RMSE(pred = predict.rf.count, obs = testing$count)
```

```{r rmse2}
RMSE(pred = predict.rf.count.add, obs = testing$count)
```

## Model Training, Prediction & Evaluation - 2

This time we will remove Features having variable importance less than 5% for each model and see if it improves our models.

First we will Configure parallel processing

```{r parallel_cluster_2}
ncluster <- makeCluster(detectCores() - 1)
registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split_2}
set.seed(777)

sample.train.data <- sample_n(train.data, size = 2000)
    
inTraining <- createDataPartition(y = sample.train.data$count, 
                                  p = 0.75, list = F)
training <- sample.train.data[inTraining, ]
testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split_2}
# set.seed(777)
# 
# inTraining <- createDataPartition(y = train.data$count, 
#                                   p = 0.75, list = F)
# training <- train.data[inTraining, ]
# testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features_2}
feature.list.casual2 <- c(4:6, 13:17, 21)
feature.list.reg2 <- c(4:6, 13:14, 16:17, 21)
feature.list.count2 <- c(4:6, 13:14, 16:17, 21)
```


Setting train control and grid parameters

```{r train_control_2}
tr.ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5,
                        verboseIter = T, allowParallel = T)

grid.rf <- expand.grid(.mtry = c(2, 4, 8))
```

Training model

```{r train_model_2, message=FALSE, warning=FALSE }
set.seed(777)
fit.rf.casual2 <- train(x = training[feature.list.casual2], y = training$casual, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.reg2 <- train(x = training[feature.list.reg2], y = training$registered, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)

set.seed(777)
fit.rf.count2 <- train(x = training[feature.list.count2], y = training$count, 
                method = 'rf', metric = 'RMSE', importance = T,
                trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the model

```{r model_evaluation_2}
resamps <- resamples(list(RF.Casual1 = fit.rf.casual, 
                          RF.Casual2 = fit.rf.casual2,
                          RF.Reg1 = fit.rf.reg,
                          RF.Reg2 = fit.rf.reg2,
                          RF.Count = fit.rf.count,
                          RF.Count2 = fit.rf.count2))
summary(resamps)
```

By removing the weaker features, the model has improved.

Variable Importance

```{r variable_importance1_2}
varImp(object = fit.rf.casual2, scale = T)
```

```{r variable_importance2_2}
varImp(object = fit.rf.reg2, scale = T)
```

```{r variable_importance3_2}
varImp(object = fit.rf.count2, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop_2}
stopCluster(ncluster)
registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict_2}
predict.rf.casual2 <- predict(fit.rf.casual2, 
                              newdata = testing[feature.list.casual2])
predict.rf.reg2 <- predict(fit.rf.reg2, 
                           newdata = testing[feature.list.reg2])
predict.rf.count2 <- predict(fit.rf.count2, 
                             newdata = testing[feature.list.count2])
predict.rf.count.add2 <- predict.rf.casual2 + predict.rf.reg2
```

Lets evaluate our model

```{r rmse_2}
RMSE(pred = predict.rf.count2, obs = testing$count)
```

```{r rmse2_2}
RMSE(pred = predict.rf.count.add2, obs = testing$count)
```

## Model Training, Prediction & Evaluation - 3

This time we will try tuning the models further and see if it improves our models.

First we will Configure parallel processing.

```{r parallel_cluster_3}
# ncluster <- makeCluster(detectCores() - 1)
# registerDoParallel(ncluster)
```


Splitting training and testing datasets

```{r sample_train_test_split_3}
# set.seed(777)
# 
# sample.train.data <- sample_n(train.data, size = 2000)
#     
# inTraining <- createDataPartition(y = sample.train.data$count, 
#                                   p = 0.75, list = F)
# training <- sample.train.data[inTraining, ]
# testing <- sample.train.data[-inTraining, ]
```

```{r train_test_split_3}
# set.seed(777)
# 
# inTraining <- createDataPartition(y = train.data$count, 
#                                   p = 0.75, list = F)
# training <- train.data[inTraining, ]
# testing <- train.data[-inTraining, ]
```

Choosing Features to use in model

```{r features_3}
# feature.list.casual3 <- c(2, 5:6, 11:15, 17)
# feature.list.reg3 <- c(2:3, 5:6, 11:12, 14:15, 17)
# feature.list.count3 <- c(2, 5:6, 11:12, 14:15, 17)
```


Setting train control and grid parameters

```{r train_control_3}
# tr.ctrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 10,
#                         verboseIter = T, allowParallel = T)
# 
# grid.rf <- expand.grid(.mtry = c(5, 7, 9, 12, 14))
```

Training model

```{r train_model_3, message=FALSE, warning=FALSE }
# set.seed(777)
# fit.rf.casual3 <- train(x = training[feature.list.casual3], y = training$casual, 
#                 method = 'rf', metric = 'RMSE', importance = T, verbose = T,
#                 trControl = tr.ctrl, tuneGrid = grid.rf)
# 
# set.seed(777)
# fit.rf.reg3 <- train(x = training[feature.list.reg3], y = training$registered, 
#                 method = 'rf', metric = 'RMSE', importance = T, verbose = T,
#                 trControl = tr.ctrl, tuneGrid = grid.rf)
# 
# set.seed(777)
# fit.rf.count3 <- train(x = training[feature.list.count3], y = training$count, 
#                 method = 'rf', metric = 'RMSE', importance = T, verbose = T,
#                 trControl = tr.ctrl, tuneGrid = grid.rf)
```


Evaluating the model

```{r model_evaluation_3}
# resamps <- resamples(list(RF.Casual1 = fit.rf.casual, 
#                           RF.Casual2 = fit.rf.casual2,
#                           RF.Casual3 = fit.rf.casual3,
#                           RF.Reg1 = fit.rf.reg,
#                           RF.Reg2 = fit.rf.reg2,
#                           RF.Reg3 = fit.rf.reg3,
#                           RF.Count1 = fit.rf.count,
#                           RF.Count2 = fit.rf.count2,
#                           RF.Count3 = fit.rf.count3))
# summary(resamps)
```



Variable Importance

```{r variable_importance1_3}
# varImp(object = fit.rf.casual3, scale = T)
```

```{r variable_importance2_3}
# varImp(object = fit.rf.reg3, scale = T)
```

```{r variable_importance3_3}
# varImp(object = fit.rf.count3, scale = T)
```

De-registering parallel processing cluster

```{r parallel_cluster_stop_3}
# stopCluster(ncluster)
# registerDoSEQ()
```

Lets run the model on our testing split.

```{r predict_3}
# predict.rf.casual3 <- predict(fit.rf.casual3, 
#                               newdata = testing[feature.list.casual3])
# predict.rf.reg3 <- predict(fit.rf.reg3, 
#                            newdata = testing[feature.list.reg3])
# predict.rf.count3 <- predict(fit.rf.count3, 
#                              newdata = testing[feature.list.count3])
# predict.rf.count.add3 <- predict.rf.casual3 + predict.rf.reg3
```

Lets evaluate our model

```{r rmse_3}
# RMSE(pred = predict.rf.count3, obs = testing$count)
```

```{r rmse2_3}
# RMSE(pred = predict.rf.count.add3, obs = testing$count)
```


## Final Prediction & Submission

We need to apply the same pre-processing steps to Test data as we did with Train data.

Splitting datetime into year, month, day_num, day_name, hour

```{r split_date_test}
test.data <- split_date(test.data)
```

Adding new column, temp.div <- temp / atemp

```{r temp_div_test}
test.data <- test.data %>%
    mutate(temp.div = temp / atemp)
```

Adding new column, day.type -- working day, holiday or weekend

```{r day_type_test}
test.data <- day_type(test.data) %>% select(-holiday, -workingday)
```

Now that pre-processing the test data is complete, lets run the predict the output.

First, creating feature list for test data

```{r features_test}
feature.list.casual.test <- c(4:6, 8:9, 11:12, 14, 16)
feature.list.reg.test <- c(4:6, 8:9, 12, 14, 16)
feature.list.count.test <- c(4:6, 8:9, 12, 14, 16)
```

Making Prediction

```{r predict_test}
predict.rf.casual.test <- predict(fit.rf.casual2, 
                              newdata = test.data[feature.list.casual.test])
predict.rf.reg.test <- predict(fit.rf.reg2, 
                           newdata = test.data[feature.list.reg.test])
predict.rf.count.test <- predict(fit.rf.count2, 
                             newdata = test.data[feature.list.count.test])
predict.rf.count.add.test <- predict.rf.casual.test + predict.rf.reg.test
```

Creating Submission Files

```{r Submission}
test.data$count <- predict.rf.count.test
test.data$count.add <- predict.rf.count.add.test

test.data %>% select(datetime, count) %>%
    write.csv(file = './Output/submit_sample_count.csv', 
              quote = F, row.names = F)

test.data %>% mutate(count = count.add) %>%
    select(datetime, count) %>%
    write.csv(file = './Output/submit_sample_count_add.csv', 
              quote = F, row.names = F)

```

